{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO371 Problem Set 4: logistic regression, SVM, classi􏰀cation\n",
    "Your name: Yasmine\n",
    "Deadline: Tue, Mar 5 midnight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This is the last problem set of this course 􏰇And you will again work with rotten tomatoes. The good news are that you already know this dataset somewhat. However, now we will explore the data a little bit more, and thereafter you will implement your own brand new shiny Naive Bayes to categorize the quotes into rotten/fresh, and 􏰀nd the optimal smoothing parameters with your own brand-even-newer and even-􏰆ashier k-fold cross validation. We also implement the three-fold data split with test data set aside for the 􏰀nal performance measure only.\n",
    "\n",
    "Please submit a) your code (notebooks, rmd, whatever) and b) the results in a 􏰀nal output form (html or pdf). You are free to choose either R or python for solving this problem set.\n",
    "\n",
    "You are welcome to answer some of the questions on paper but please include the result as an image in your 􏰀nal 􏰀le. Note that you can easily include images in both notebooks and .rmd􏰅besides of the code, both are just markdown documents.\n",
    "\n",
    "Working together is fun and useful but you have to submit your own work. Discussing the solutions and problems with your classmates is all right but do not copy-paste their solution! Please list all your collaborators below:\n",
    "\n",
    "1. Kishore Vasan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotten Tomatoes\n",
    "Our fi􏰀rst task is to load, clean and explore the Rotten Tomatoes movie reviews data. Please familiarize yourself a little bit with the webpage. Brie􏰆y, approved critics can write reviews for movies, and evaluate the movie as 􏰁fresh􏰂 or 􏰁rotten􏰂. The webpage normally shows a short 􏰁quote􏰂 from each critic, and whether it was evaluated as fresh or rotten. You will work on these quotes below.\n",
    "\n",
    "The central variables in rotten-tomatoes.csv are the following: \n",
    "\n",
    "**critic** name of the critic\n",
    "\n",
    "**fresh** evaluation: 'fresh' or 'rotten'\n",
    "\n",
    "**quote** short version of the review\n",
    "\n",
    "**review_date** when the review was written\n",
    "\n",
    "There are more variables like links to IMDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "Load data and split it into working and testing chunks. But before you begin: ensure you can save a dataframe in a format you can load back in afterwards. pd.to_csv is a good bet, but it has a lot of options which may screw up the way you read data. Ensure you can store data in a way that you can read it back in correctly, including that missings remain missings.\n",
    "\n",
    "1) create a tiny toy data frame that includes some numbers, strings, and missings. Save it and ensure you can reload it in the correct form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name   Age\n",
      "0  jon  25.0\n",
      "1  tom  40.0\n",
      "2  bob   NaN\n"
     ]
    }
   ],
   "source": [
    "data = [['jon', 25], ['tom', 40], ['bob', ]] \n",
    "df = pd.DataFrame(data, columns = ['Name', 'Age'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf='toy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name   Age\n",
      "0  jon  25.0\n",
      "1  tom  40.0\n",
      "2  bob   NaN\n"
     ]
    }
   ],
   "source": [
    "toy = pd.read_csv(\"toy.csv\")\n",
    "print(toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are good to go:\n",
    "\n",
    "2) load the data (available on canvas: 􏰀les/data/rotten-tomatoes.csv). DO NOT LOOK AT IT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 13442\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "rotten = pd.read_csv(\"reviews.csv\")\n",
    "print(\"Number of cases:\", len(rotten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) split the dataset into working-testing parts (80/20 or so). Note that sklearn's train_test_split can easily handle dataframes. Just for your con􏰀rmation, ensure that the size of the working and testing data look reasonable.\n",
    "\n",
    "4) now save the test data and delete it from memory. Use python's del statement, or R-s rm function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(rotten, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train: 10753\n",
      "Length of test: 2689\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train:\", len(train))\n",
    "print(\"Length of test:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(path_or_buf='test.csv', index = False)\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore and clean the data\n",
    "Now when the test data is put aside, we can breath out and take a closer look how does the work data look like.\n",
    "\n",
    "1) Take a look at a few lines of data (you may use pd.sample for this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>53459</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>As absurd and as beautiful as a fairy tale.</td>\n",
       "      <td>2007-09-26 00:00:00</td>\n",
       "      <td>770698712</td>\n",
       "      <td>Eyes Without a Face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>46250</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The newcomer named Audrey Hepburn gives the po...</td>\n",
       "      <td>2009-02-02 00:00:00</td>\n",
       "      <td>18129</td>\n",
       "      <td>Roman Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11132</th>\n",
       "      <td>Kenneth Turan</td>\n",
       "      <td>fresh</td>\n",
       "      <td>132347</td>\n",
       "      <td>http://www.calendarlive.com/movies/reviews/cl-...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>An effort you end up admiring more than comple...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>10623</td>\n",
       "      <td>Mystery Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>Kevin Thomas</td>\n",
       "      <td>rotten</td>\n",
       "      <td>174204</td>\n",
       "      <td>http://www.calendarlive.com/movies/reviews/cl-...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>Much effort and expertise have gone into the m...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>15698</td>\n",
       "      <td>Simpatico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>fresh</td>\n",
       "      <td>91867</td>\n",
       "      <td>http://www.rogerebert.com/reviews/a-room-with-...</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>It is an intellectual film, but intellectual a...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>17636</td>\n",
       "      <td>A Room With A View</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   critic   fresh    imdb  \\\n",
       "3372   Jonathan Rosenbaum   fresh   53459   \n",
       "3669                  NaN   fresh   46250   \n",
       "11132       Kenneth Turan   fresh  132347   \n",
       "13084        Kevin Thomas  rotten  174204   \n",
       "5507          Roger Ebert   fresh   91867   \n",
       "\n",
       "                                                    link        publication  \\\n",
       "3372   http://onfilm.chicagoreader.com/movies/capsule...     Chicago Reader   \n",
       "3669   http://www.time.com/time/magazine/article/0,91...      TIME Magazine   \n",
       "11132  http://www.calendarlive.com/movies/reviews/cl-...  Los Angeles Times   \n",
       "13084  http://www.calendarlive.com/movies/reviews/cl-...  Los Angeles Times   \n",
       "5507   http://www.rogerebert.com/reviews/a-room-with-...  Chicago Sun-Times   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "3372         As absurd and as beautiful as a fairy tale.  2007-09-26 00:00:00   \n",
       "3669   The newcomer named Audrey Hepburn gives the po...  2009-02-02 00:00:00   \n",
       "11132  An effort you end up admiring more than comple...  2000-01-01 00:00:00   \n",
       "13084  Much effort and expertise have gone into the m...  2000-01-01 00:00:00   \n",
       "5507   It is an intellectual film, but intellectual a...  2000-01-01 00:00:00   \n",
       "\n",
       "            rtid                title  \n",
       "3372   770698712  Eyes Without a Face  \n",
       "3669       18129        Roman Holiday  \n",
       "11132      10623          Mystery Men  \n",
       "13084      15698            Simpatico  \n",
       "5507       17636   A Room With A View  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) print out all variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable names: \n",
      " ['critic', 'fresh', 'imdb', 'link', 'publication', 'quote', 'review_date', 'rtid', 'title']\n"
     ]
    }
   ],
   "source": [
    "print('Variable names: \\n', list(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) create a summary table (maybe more like a bullet list) where you print out the most important summary statistics for the most interesting variables. The most interesting facts you should present should include: a) number of missings for fresh and quote; b) all diff􏰄erent values for fresh/rotten evaluations; c) counts or percentages of these values; d) number of zero-length or only whitespace quote-s; e) minimum-maximum-average length of quotes (either in words, or in characters). (Can you do this as an one-liner?); f) how many reviews are in data multiple times. Feel free to add more fi􏰀gures you consider relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of missings for fresh and quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critic         572\n",
      "fresh            0\n",
      "imdb             0\n",
      "link             0\n",
      "publication      0\n",
      "quote            0\n",
      "review_date      0\n",
      "rtid             0\n",
      "title            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na = train.isnull().sum()\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all diff􏰄erent values for fresh/rotten evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different evaluation values: \n",
      " ['fresh' 'rotten' 'none']\n"
     ]
    }
   ],
   "source": [
    "print('Different evaluation values: \\n', train.fresh.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- counts or percentages of these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages of evaluation values: \n",
      " fresh     62.140798\n",
      "rotten    37.682507\n",
      "none       0.176695\n",
      "Name: fresh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Percentages of evaluation values: \\n', train['fresh'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of zero-length or only whitespace quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero-length quotes: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of zero-length quotes:', len(train[train.quote.str.len() == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- minimum-maximum-average length of quotes (either in words, or in characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of quote: 256\n",
      "Minimum length of quote: 6\n",
      "Average length of quote: 121.49\n"
     ]
    }
   ],
   "source": [
    "field_length = train.quote.astype(str).map(len)\n",
    "print('Maximum length of quote:', len(train.loc[field_length.argmax(), 'quote']))\n",
    "print('Minimum length of quote:', len(train.loc[field_length.argmin(), 'quote']))\n",
    "print('Average length of quote:', round(field_length.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how many reviews are in data multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 386\n"
     ]
    }
   ],
   "source": [
    "print('Number of duplicates:', len(train[train.duplicated() == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feel free to add more fi􏰀gures you consider relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count          mean           std      min    median          max\n",
      "imdb  10753.0  1.559055e+05  1.669296e+05  13442.0  114113.0    1190539.0\n",
      "rtid  10753.0  6.038135e+07  1.878349e+08     11.0   13380.0  771031792.0\n"
     ]
    }
   ],
   "source": [
    "# Get other summary stats\n",
    "summary = train.describe().transpose()\n",
    "summary.columns = ['count','mean','std','min','25%','median','75%','max']\n",
    "summary = summary[['count','mean','std','min','median','max']]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Now when you have an overview what you have in data, clean it by removing all the inconsistencies the table reveals. We have to ensure that the central variables: quote and fresh are not missing, and quote is not an empty string (or just contain spaces and such).\n",
    "\n",
    "I strongly recommend to do it as a standalone function because at the end you have to perform exactly the same cleaning operations with your test data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    # remove 'none' for fresh\n",
    "    df = df[df['fresh'] != 'none']\n",
    "    # remove missing quotes?\n",
    "    df = df[df.quote.str.len() > 0]\n",
    "    # remove duplicates\n",
    "    df.drop_duplicates(keep=False, inplace=True) \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = clean(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naïve Bayes\n",
    "Now where you are familiar with the data, it's time to get serious and implement the Naive Bayes classi􏰀er from scratch. But fi􏰀rst things fi􏰀rst.\n",
    "\n",
    "1) Ensure you are familiar with Naive Bayes. Consult the readings, available on canvas. Schutt & O'Neill is an easy and accessible (and long) introduction, Whitten & Frank is a lot shorter but still accessible introduction.\n",
    "\n",
    "2) Convert your data (quotes) into bag-of-words. Your code should look something along the lines as in PS4. However, now we don't want BOW that contains counts of words in quotes, but just 1/0 (or true/- false) for the presence/non-presence of the words. Convert the count-based BOW into such a presence BOW. Hint: think in terms of vectorized (universal) functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]] \n",
      "\n",
      "Number of rows: 9984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initialize the vectorizer\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "# create the dictionary\n",
    "vectorizer.fit(train_clean.quote)\n",
    "\n",
    "\n",
    "vectorizer.fit_transform(train_clean[\"quote\"]).toarray()\n",
    "\n",
    "# `fit` builds the vocabulary\n",
    "# transform your data into the BOW array\n",
    "#X = vectorizer.transform(train_clean.quote).toarray()\n",
    "\n",
    "words_list = list(vectorizer.get_feature_names())\n",
    "\n",
    "print(X, '\\n')\n",
    "print('Number of rows:', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Split your work data and target (i.e. the variable fresh) into training and validation chunks (80/20 or so). Later we also do cross-validation, but for now, a simple training/validation will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vtrain, val = train_test_split(train_clean, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now you are ready with the preparatory work and it's time to dive into the real thing. Let's implement Naive Bayes. Use only training data in the fi􏰀tting below.\n",
    "\n",
    "4) Compute the unconditional (log) probability that the tomato is fresh/rotten, log Pr(F), and log Pr(R). These probabilities are based on the values of fresh variable but not on the words the quotes contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fresh    -0.487356\n",
       "rotten   -0.952561\n",
       "Name: fresh, dtype: float64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = vtrain['fresh'].value_counts(normalize=True)\n",
    "np.log(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) For each word w, compute log Pr(w|F) and log Pr(w|R), the (log) probability that the word is present in a fresh/rotten review. These probabilities can easily be calculated from counts of how many times these words are present for each class.\n",
    "\n",
    "Hint: these computations are based on your BOW-s X. Look at ways to sum along columns in this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw probability:\n",
      "pr(w|f):\n",
      " [ 0.25        1.          0.71428571 ...,  0.          0.66666667  0.        ] \n",
      "\n",
      "pr(w|r):\n",
      " [ 0.75        0.          0.28571429 ...,  1.          0.33333333  1.        ] \n",
      "\n",
      "Log probabilities:\n",
      "log pr(w|f):\n",
      " [-1.38629436  0.         -0.33647224 ...,        -inf -0.40546511\n",
      "        -inf] \n",
      "\n",
      "log pr(w|r):\n",
      " [-0.28768207        -inf -1.25276297 ...,  0.         -1.09861229  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasmine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/yasmine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "pr_fr = vtrain.fresh.value_counts(normalize=True)\n",
    "pr_f, pr_r = np.log(pr_fr)\n",
    "\n",
    "# get the indices that contain fresh or rotten\n",
    "boolean_fresh = [1 if i == 'fresh' else 0 for i in train_clean.fresh]\n",
    "fresh_indices = []\n",
    "rotten_indices = []\n",
    "\n",
    "for i, j in enumerate(boolean_fresh):\n",
    "    if j == 1:\n",
    "        fresh_indices.append(i)\n",
    "    else:\n",
    "        rotten_indices.append(i)\n",
    "        \n",
    "# probability of w|fresh\n",
    "pr_w_f = np.divide(X[np.array(fresh_indices),:].sum(axis = 0).astype(float),X.sum(axis = 0).astype(float))\n",
    "\n",
    "# probability of w|rotten\n",
    "pr_w_r = np.divide(X[np.array(rotten_indices),:].sum(axis = 0).astype(float),X.sum(axis = 0).astype(float))\n",
    "\n",
    "print('Raw probability:')\n",
    "print('pr(w|f):\\n', pr_w_f, '\\n')\n",
    "print(\"pr(w|r):\\n\", pr_w_r, '\\n')\n",
    "\n",
    "\n",
    "# take the log of probability\n",
    "pr_w_f = np.log(pr_w_f)\n",
    "pr_w_r = np.log(pr_w_r)\n",
    "print('Log probabilities:')\n",
    "print('log pr(w|f):\\n', pr_w_f, '\\n')\n",
    "print('log pr(w|r):\\n', pr_w_r, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done with the estimator. Your fitted model is completely described by these four probability vectors: log Pr(F), log Pr(R), log Pr(w|F), log Pr(w|R). Let's now turn to prediction, and pull out your validation data (not the test data!).\n",
    "\n",
    "6) For both destination classes, F and R, compute the log-likelihood that the quote belongs to this class. I think we mentioned log-likelihood in the class, it is what is given inside the brackets in equation (1) on slide 28, and the equations on Schutt 􏰁Doing Data Science􏰂, page 102. On the slides we have the log-likelihood essentially as (although we do not write it out):\n",
    "\n",
    "􏰈\n",
    "li(c) = log Pr(c) + where c ∈ {F, R} is the class, i is the review, j indexes words, and wij is the j-th word of the review\n",
    "i.\n",
    "\n",
    "Computing these likelihoods involves sums of the previously computed probabilities, log Pr(w|F), and BOW elements xij. Check out np.apply_along_axis (or R's apply) that can be used to apply a function on matrix columns/rows so you can create a fairly good one-liner to compute log-likelihood. Loops are 􏰀ne too, just slower and less compact.\n",
    "\n",
    "\n",
    "Based on the log-likelihoods, predict the class F or R for each quote in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(quote):\n",
    "    words = quote.split(' ')\n",
    "    word_idx = []\n",
    "    for i in words:\n",
    "        if i in words_list:\n",
    "            word_idx.append(words_list.index(i))\n",
    "    tmp_p_f = pr_f\n",
    "    tmp_p_r = pr_r\n",
    "\n",
    "    if len(word_idx)>0:\n",
    "        tmp_p_f += np.sum(pr_w_f[np.array(word_idx)])\n",
    "        tmp_p_r += pr_r + np.sum(pr_w_r[np.array(word_idx)])\n",
    "    \n",
    "    if tmp_p_f > tmp_p_r:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# use vtrain to predict\n",
    "predicted = vtrain.quote.apply(predict).to_frame().quote\n",
    "predicted = list(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Print the resulting confusion matrix and accuracy (feel free to use existing libraries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 81.59509202453987\n",
      "Confusion Matrix:\n",
      "[[1611 1470]\n",
      " [   0 4906]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y = [1 if i == 'fresh' else 0 for i in vtrain.fresh]\n",
    "output = [a == p for a,p in zip(predicted,y)]\n",
    "accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "matrix = confusion_matrix(y, predicted)\n",
    "print('Accuracy of the model:', accuracy)\n",
    "print('Confusion Matrix:')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interpretation\n",
    "Now it is time to look at your fi􏰀tted model a little bit closer. NB model probabilities are rather easy to understand and interpret. The task here is to 􏰀nd the best words to predict a fresh, and a rotten review. And we only want to look at words that are reasonably frequent, say more frequent than 30 times in the data.\n",
    "\n",
    "1) Extract from your conditional probability vectors log Pr(F) and log Pr(R) the probabilities that cor- respond to frequent words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_X = X[np.array(fresh_indices),:]\n",
    "fresh_freq_idx = [i for (i,j) in enumerate(list(fresh_X.sum(axis = 0) >30)) if j == True]\n",
    "\n",
    "rotten_X = X[np.array(rotten_indices),:]\n",
    "rotten_freq_idx = [i for (i,j) in enumerate(list(rotten_X.sum(axis = 0) >30)) if j == True]\n",
    "\n",
    "# log probability vectors of frequent words\n",
    "top_p_f = pr_w_f[np.array(fresh_freq_idx)]\n",
    "top_p_r = pr_w_r[np.array(rotten_freq_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Find 10 best words to predict F and 10 best words to predict R. Hint: imagine we have a review that contains just a single word. Which word will give the highest weight to the probability the review is fresh? Which one to the likelihood it is rotten?\n",
    "\n",
    "Comment your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top fresh words:\n",
      " ['mumford', 'chafing', 'cesare', 'munro', 'cesar', 'murderer', 'certifiably', 'murkiness', 'murnau', 'largest']\n",
      "Top rotten words:\n",
      " ['kinkiness', 'kidnapping', 'kidron', 'kiel', 'killings', 'kin', 'kinberg', 'kinder', 'staginess', 'zzzzzzzzz']\n"
     ]
    }
   ],
   "source": [
    "top_f_idx = np.argsort(pr_w_f)[-10:]\n",
    "top_r_idx = np.argsort(pr_w_r)[-10:]\n",
    "\n",
    "top_f_words = [words_list[i] for i in top_f_idx]\n",
    "top_r_words = [words_list[i] for i in top_r_idx]\n",
    "\n",
    "print('Top fresh words:\\n', top_f_words)\n",
    "print('Top rotten words:\\n', top_r_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the top 10 words for fresh and rotten. For fresh, the top word is *mumford* and for rotten, the top word is *kinkiness*. We see some strange words, as described in the next prompt. This is because as mentioned above, when we have a review that contains just a single word, that word gains a lot of the weight. If a word also only appears once in the whole set, it will likely be classified as the only thing it was ever classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Print out a few missclassi􏰀ed quotes. Can you understand why these are misclassi􏰀ed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words from our top words, such as 'chafing,' 'mumford,' or 'zzzzzzzzz' appear to be misclassified because they do not really have any influence of the review really being \"fresh.\"\n",
    "\n",
    "We can probably attribute these words being misclassified becuase of the possibility that the words only appear once in the quotes. A review with only one word would also give that word a lot of weight in the model. This would mean that the BOW gives 100% or 0% probability of that word being what it was only classified as or has more weight from, hence some strange words coming into our top 10 \"fresh\" and \"rotten\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NB with smoothing\n",
    "So, now you have your brand-new NB algorithm up and running. As a next step, we add smoothing to it. As you will be doing cross-validation below, your 􏰀first task is to mold what you did above into two funcions: one for 􏰀fitting and another one for predicting.\n",
    "\n",
    "1) Create two functions: one for fi􏰀tting NB model, and another to predict outcome based on the fi􏰀tted model.\n",
    "\n",
    "As mentioned above, the model is fully described with 4 probabilities, so your fitting function may return such a list as the model; and the prediction function may take it as an input.\n",
    "\n",
    "2) Add smoothing to the model. See Schutt p 103 and 109. Smoothing amounts to assuming that we have 􏰁seen􏰂 every possible work α 􏰉 0 times already, for both classes. (If you wish, you can also assume you have seen the words α times for F and β times for R). Note that α does not have to be an integer, and typically the best α < 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fitNB(X_train, y_train, alpha):\n",
    "    global p_fresh, p_rotten, l_p_f, l_p_r, words_list\n",
    "    \n",
    "    # initialize the vectorizer\n",
    "    vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "    # create the dictionary\n",
    "    vectorizer.fit(X_train)\n",
    "\n",
    "    # `fit` builds the vocabulary\n",
    "    # transform your data into the BOW array\n",
    "    X = vectorizer.transform(X_train).toarray()\n",
    "    words_list = list(vectorizer.get_feature_names())\n",
    "\n",
    "    n_fresh = np.sum(y_train == 'fresh') + alpha\n",
    "    n_rotten = np.sum(y_train == 'rotten') + alpha\n",
    "    n_total = n_fresh + n_rotten\n",
    "    p_fresh = float(n_fresh) / float(n_total)\n",
    "    p_rotten = float(n_rotten) / float(n_total)\n",
    "    f_counts = X[y_train == 'fresh'].sum(axis = 0) + alpha\n",
    "    r_counts = X[y_train == 'rotten'].sum(axis = 0) + alpha\n",
    "    l_p_f = np.log(f_counts / n_fresh)\n",
    "    l_p_r = np.log(r_counts / n_rotten)\n",
    "    return p_fresh, p_rotten, l_p_f, l_p_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictNB(quote):\n",
    "    words = quote.split(' ')\n",
    "    word_idx = []\n",
    "    for i in words:\n",
    "        if i in words_list:\n",
    "            word_idx.append(words_list.index(i))\n",
    "    tmp_p_f = p_fresh\n",
    "    tmp_p_r = p_rotten\n",
    "    \n",
    "    if len(word_idx)>0:\n",
    "        tmp_p_f += np.sum(l_p_f[np.array(word_idx)])\n",
    "        tmp_p_r += pr_r + np.sum(l_p_r[np.array(word_idx)])\n",
    "    \n",
    "    # if prob of fresh is greater than prob of rotten\n",
    "    if tmp_p_f > tmp_p_r:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Now 􏰀fit a few models with different α-s and see if the accuracy improves compared to the baseline case above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasmine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/yasmine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0\n",
      "Accuracy of the model: 65.7486229344016\n",
      "Alpha: 0.1\n",
      "Accuracy of the model: 70.85628442663996\n",
      "Alpha: 0.2\n",
      "Accuracy of the model: 71.65748622934402\n",
      "Alpha: 0.3\n",
      "Accuracy of the model: 72.15823735603405\n",
      "Alpha: 0.4\n",
      "Accuracy of the model: 72.15823735603405\n",
      "Alpha: 0.5\n",
      "Accuracy of the model: 72.30846269404107\n",
      "Alpha: 0.6\n",
      "Accuracy of the model: 72.15823735603405\n",
      "Alpha: 0.7\n",
      "Accuracy of the model: 72.45868803204807\n",
      "Alpha: 0.8\n",
      "Accuracy of the model: 72.45868803204807\n",
      "Alpha: 0.9\n",
      "Accuracy of the model: 72.40861291937907\n",
      "Alpha: 1\n",
      "Accuracy of the model: 72.50876314471708\n"
     ]
    }
   ],
   "source": [
    "X_quote = vtrain.quote\n",
    "y = vtrain.fresh\n",
    "\n",
    "y_output = val.fresh\n",
    "y_output = [1 if i == 'fresh' else 0 for i in y_output]\n",
    "\n",
    "for al in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "    fitNB(X_quote, y, al)\n",
    "    predicted = val.quote.apply(predictNB).to_frame().quote\n",
    "    predicted = list(predicted)\n",
    "    # finding accuracy\n",
    "    output = [a == p for a,p in zip(predicted,y_output)]\n",
    "    accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "    print('Alpha:', al)\n",
    "    print('Accuracy of the model:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation\n",
    "Finally (well, almost 􏰀finally), we do cross-validation. This is another piece of code you have to implement yourself, not use existing libraries.\n",
    "\n",
    "- Implement k-fold CV. I recommend to implement it as a function that a) puts your data into random order; b) splits these into k chunks; c) selects a chunk for testing and the others for training; d) trains your NB model on the training chunks; e) computes accuracy on training chunk; f) returns mean accuracy over all these k trials. The function should also take α as an argument, this is the hyperparameter you are going to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_frame(df, num_chunks): \n",
    "    listOfDf = list()\n",
    "    chunk_size = len(df) // num_chunks\n",
    "    for i in range(num_chunks):\n",
    "        listOfDf.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return listOfDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(data, k, alpha):\n",
    "    print('Number of chunks:', k)\n",
    "    print('Alpha:', alpha)\n",
    "    \n",
    "    chunks = split_data_frame(data, k)\n",
    "    accuracy_list = []\n",
    "    for chunk_df in chunks:\n",
    "        tmp_train = data[~data.isin(chunk_df)]\n",
    "        X_quote = tmp_train.quote.astype(str)\n",
    "        y = tmp_train.fresh\n",
    "\n",
    "        y_output = chunk_df.fresh\n",
    "        y_output = [1 if i == 'fresh' else 0 for i in y_output]\n",
    "\n",
    "        fitNB(X_quote, y, alpha)\n",
    "        predicted = chunk_df.quote.apply(predictNB).to_frame().quote\n",
    "        predicted = list(predicted)\n",
    "\n",
    "        # finding accuracy\n",
    "        output = [a == p for a,p in zip(predicted,y_output)]\n",
    "        accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "        accuracy_list.append(accuracy)\n",
    "       \n",
    "        print('Accuracy:', accuracy)\n",
    "    print('Average accuracy:', np.mean(accuracy_list))\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the optimal α by 5-fold CV using your own CV code. You have to fi􏰀nd the cross-validated accuracies for a number of α-s between 0 and 1. Present the accuracy as a function of α on a plot and indicate which one is the best α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5\n",
      "Alpha: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasmine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/yasmine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.98597194388778\n",
      "Accuracy: 67.08416833667334\n",
      "Accuracy: 65.03006012024048\n",
      "Accuracy: 66.18236472945893\n",
      "Accuracy: 66.38276553106212\n",
      "Average accuracy: 66.5330661323\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.1\n",
      "Accuracy: 71.29258517034069\n",
      "Accuracy: 72.29458917835672\n",
      "Accuracy: 69.83967935871743\n",
      "Accuracy: 69.73947895791584\n",
      "Accuracy: 70.49098196392785\n",
      "Average accuracy: 70.7314629259\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.2\n",
      "Accuracy: 72.24448897795591\n",
      "Accuracy: 72.59519038076152\n",
      "Accuracy: 69.93987975951904\n",
      "Accuracy: 70.29058116232466\n",
      "Accuracy: 70.79158316633266\n",
      "Average accuracy: 71.1723446894\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.3\n",
      "Accuracy: 72.89579158316634\n",
      "Accuracy: 72.94589178356713\n",
      "Accuracy: 70.44088176352705\n",
      "Accuracy: 70.19038076152304\n",
      "Accuracy: 71.14228456913828\n",
      "Average accuracy: 71.5230460922\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.4\n",
      "Accuracy: 72.84569138276554\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 70.74148296593187\n",
      "Accuracy: 70.39078156312625\n",
      "Accuracy: 71.09218436873748\n",
      "Average accuracy: 71.623246493\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.5\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 73.24649298597194\n",
      "Accuracy: 70.84168336673346\n",
      "Accuracy: 70.64128256513025\n",
      "Accuracy: 71.29258517034069\n",
      "Average accuracy: 71.8136272545\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.6\n",
      "Accuracy: 73.29659318637275\n",
      "Accuracy: 73.49699398797596\n",
      "Accuracy: 71.09218436873748\n",
      "Accuracy: 71.04208416833667\n",
      "Accuracy: 71.59318637274549\n",
      "Average accuracy: 72.1042084168\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.7\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 73.39679358717434\n",
      "Accuracy: 71.34268537074149\n",
      "Accuracy: 71.24248496993988\n",
      "Accuracy: 71.4929859719439\n",
      "Average accuracy: 72.1042084168\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.8\n",
      "Accuracy: 73.19639278557113\n",
      "Accuracy: 73.24649298597194\n",
      "Accuracy: 71.34268537074149\n",
      "Accuracy: 71.34268537074149\n",
      "Accuracy: 71.44288577154309\n",
      "Average accuracy: 72.1142284569\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.9\n",
      "Accuracy: 73.14629258517033\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 71.39278557114228\n",
      "Accuracy: 71.19238476953907\n",
      "Accuracy: 71.5430861723447\n",
      "Average accuracy: 72.0641282565\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 1\n",
      "Accuracy: 73.29659318637275\n",
      "Accuracy: 72.99599198396794\n",
      "Accuracy: 71.59318637274549\n",
      "Accuracy: 70.99198396793587\n",
      "Accuracy: 71.7434869739479\n",
      "Average accuracy: 72.124248497\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "    cross_val(train_clean, 5, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac3a5ff28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data['alpha'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "data['acc'] = [66.53, 70.73, 71.17, 71.52, 71.62, 71.81, 72.10, 72.10, 72.11, 72.06, 72.12]\n",
    "\n",
    "plt.plot(data['alpha'], data['acc'], c = 'red')\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"average accuracy(%)\")\n",
    "plt.title(\"Alpha vs Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final model performance\n",
    "Finally (and now I mean 􏰀nally􏰇), estimate the model performance on the testing data. Complete this section after everything else is done and you are ready to submit your work. Don't improve model after you have loaded testing data!\n",
    "\n",
    "1) Fit your NB model using the cross-validated optimal alpha using your complete work data (both training and validation). This is your best and final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6156619266973763,\n",
       " 0.38433807330262365,\n",
       " array([-8.03073492, -8.03073492, -6.93212264, ..., -8.7238821 ,\n",
       "        -7.62526982, -8.7238821 ]),\n",
       " array([-6.64326876, -8.25270668, -7.15409439, ..., -7.5595595 ,\n",
       "        -7.5595595 , -7.5595595 ]))"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal alpha: 1.0\n",
    "fitNB(train_clean.quote, train_clean.fresh, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Load your testing data. Clean it using exactly the same procedure (you made a function for this, right?) and transform it into BOW-s.\n",
    "\n",
    "Note: above I suggested using vectorizer.fit_transform(quote) function to create the BOW. Here I recommend to use vectorizer.transform(quote). This is because we don't want to change the vocabulary (that's what the fit-part does), only to transform it into the BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_clean = clean(test_df)\n",
    "\n",
    "y_output = test_clean.fresh\n",
    "y_output = [1 if i == 'fresh' else 0 for i in y_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Predict the F/R class on testing data. Compute accuracy. Present it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.85736021300875\n"
     ]
    }
   ],
   "source": [
    "predicted = test_clean.quote.apply(predictNB).to_frame().quote\n",
    "predicted = list(predicted)\n",
    "\n",
    "output = [a == p for a,p in zip(predicted,y_output)]\n",
    "accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Did you get a better or worse result compared to the k-NN and TF-IDF in PS04?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got about the same accuracy (~75%) as the k-NN and TF_IDF in PS04 (for k = 5). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is it. This is your 􏰀nal model performance measure. Feel free to compare it with your peers, but even if abysmal, don't play with the model any more! Just submit, and you are done 􏰇... really done, this was your last problem set!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
