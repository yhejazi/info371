{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO371 Problem Set 6: Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this problem set, we will use the Rotton Tomatoes dataset to implement our own, brand new, shiny Naive Bayes to categorize the quotes into rotten/fresh, and find the optimal smoothing parameters with our own, brand-even-newer k-fold cross validation. We also implement the three-fold data split with test data set aside for the final performance measure only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotten Tomatoes\n",
    "Our first task is to load, clean and explore the Rotten Tomatoes movie reviews data. Briefly, approved critics can write reviews for movies, and evaluate the movie as \"fresh\" or \"rotten\". The webpage normally shows a short quote from each critic, and whether it was evaluated as fresh or rotten\n",
    "\n",
    "The central variables in rotten-tomatoes.csv are the following: \n",
    "\n",
    "**critic** name of the critic\n",
    "\n",
    "**fresh** evaluation: 'fresh' or 'rotten'\n",
    "\n",
    "**quote** short version of the review\n",
    "\n",
    "**review_date** when the review was written\n",
    "\n",
    "There are more variables like links to IMDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "Load data and split it into working and testing chunks. Before we begin, let's ensure that we can save a dataframe in a format that we can load back in afterwards. pd.to_csv is a good bet, but it has a lot of options which may screw up the way the data is read. We will ensure that we can store data in a way that we can read it back in correctly, including that missings remain missings.\n",
    "\n",
    "1) Create a tiny toy data frame that includes some numbers, strings, and missings. Save it and ensure you can reload it in the correct form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name   Age\n",
      "0  jon  25.0\n",
      "1  tom  40.0\n",
      "2  bob   NaN\n"
     ]
    }
   ],
   "source": [
    "data = [['jon', 25], ['tom', 40], ['bob', ]] \n",
    "df = pd.DataFrame(data, columns = ['Name', 'Age'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf='toy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name   Age\n",
      "0  jon  25.0\n",
      "1  tom  40.0\n",
      "2  bob   NaN\n"
     ]
    }
   ],
   "source": [
    "toy = pd.read_csv(\"toy.csv\")\n",
    "print(toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are good to go.\n",
    "\n",
    "2) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 13442\n"
     ]
    }
   ],
   "source": [
    "rotten = pd.read_csv(\"reviews.csv\")\n",
    "print(\"Number of cases:\", len(rotten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Split the dataset into working-testing parts (80/20 or so). Note that sklearn's train_test_split can easily handle dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(rotten, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train: 10753\n",
      "Length of test: 2689\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train:\", len(train))\n",
    "print(\"Length of test:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Save the test data and delete it from memory. Use python's del statement, or R-s rm function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(path_or_buf='test.csv', index = False)\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore and clean the data\n",
    "Now when the test data is put aside, we can breath out and take a closer look how does the work data look like.\n",
    "\n",
    "1) Take a look at a few lines of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>53459</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>As absurd and as beautiful as a fairy tale.</td>\n",
       "      <td>2007-09-26 00:00:00</td>\n",
       "      <td>770698712</td>\n",
       "      <td>Eyes Without a Face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>46250</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The newcomer named Audrey Hepburn gives the po...</td>\n",
       "      <td>2009-02-02 00:00:00</td>\n",
       "      <td>18129</td>\n",
       "      <td>Roman Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11132</th>\n",
       "      <td>Kenneth Turan</td>\n",
       "      <td>fresh</td>\n",
       "      <td>132347</td>\n",
       "      <td>http://www.calendarlive.com/movies/reviews/cl-...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>An effort you end up admiring more than comple...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>10623</td>\n",
       "      <td>Mystery Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>Kevin Thomas</td>\n",
       "      <td>rotten</td>\n",
       "      <td>174204</td>\n",
       "      <td>http://www.calendarlive.com/movies/reviews/cl-...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>Much effort and expertise have gone into the m...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>15698</td>\n",
       "      <td>Simpatico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>fresh</td>\n",
       "      <td>91867</td>\n",
       "      <td>http://www.rogerebert.com/reviews/a-room-with-...</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>It is an intellectual film, but intellectual a...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>17636</td>\n",
       "      <td>A Room With A View</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   critic   fresh    imdb  \\\n",
       "3372   Jonathan Rosenbaum   fresh   53459   \n",
       "3669                  NaN   fresh   46250   \n",
       "11132       Kenneth Turan   fresh  132347   \n",
       "13084        Kevin Thomas  rotten  174204   \n",
       "5507          Roger Ebert   fresh   91867   \n",
       "\n",
       "                                                    link        publication  \\\n",
       "3372   http://onfilm.chicagoreader.com/movies/capsule...     Chicago Reader   \n",
       "3669   http://www.time.com/time/magazine/article/0,91...      TIME Magazine   \n",
       "11132  http://www.calendarlive.com/movies/reviews/cl-...  Los Angeles Times   \n",
       "13084  http://www.calendarlive.com/movies/reviews/cl-...  Los Angeles Times   \n",
       "5507   http://www.rogerebert.com/reviews/a-room-with-...  Chicago Sun-Times   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "3372         As absurd and as beautiful as a fairy tale.  2007-09-26 00:00:00   \n",
       "3669   The newcomer named Audrey Hepburn gives the po...  2009-02-02 00:00:00   \n",
       "11132  An effort you end up admiring more than comple...  2000-01-01 00:00:00   \n",
       "13084  Much effort and expertise have gone into the m...  2000-01-01 00:00:00   \n",
       "5507   It is an intellectual film, but intellectual a...  2000-01-01 00:00:00   \n",
       "\n",
       "            rtid                title  \n",
       "3372   770698712  Eyes Without a Face  \n",
       "3669       18129        Roman Holiday  \n",
       "11132      10623          Mystery Men  \n",
       "13084      15698            Simpatico  \n",
       "5507       17636   A Room With A View  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Print out all variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable names: \n",
      " ['critic', 'fresh', 'imdb', 'link', 'publication', 'quote', 'review_date', 'rtid', 'title']\n"
     ]
    }
   ],
   "source": [
    "print('Variable names: \\n', list(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Create a summary table (maybe more like a bullet list) that prints out the most important summary statistics for the most interesting variables. The most interesting facts should include: \n",
    "\n",
    "a) number of missings for fresh and quote; \n",
    "b) all different values for fresh/rotten evaluations; \n",
    "c) counts or percentages of these values; \n",
    "d) number of zero-length or only whitespace quotes; \n",
    "e) minimum-maximum-average length of quotes (either in words, or in characters); \n",
    "f) how many reviews are in data multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of missings for fresh and quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critic         572\n",
      "fresh            0\n",
      "imdb             0\n",
      "link             0\n",
      "publication      0\n",
      "quote            0\n",
      "review_date      0\n",
      "rtid             0\n",
      "title            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na = train.isnull().sum()\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all different values for fresh/rotten evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different evaluation values: \n",
      " ['fresh' 'rotten' 'none']\n"
     ]
    }
   ],
   "source": [
    "print('Different evaluation values: \\n', train.fresh.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- counts or percentages of these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages of evaluation values: \n",
      " fresh     62.140798\n",
      "rotten    37.682507\n",
      "none       0.176695\n",
      "Name: fresh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Percentages of evaluation values: \\n', train['fresh'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of zero-length or only whitespace quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero-length quotes: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of zero-length quotes:', len(train[train.quote.str.len() == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- minimum-maximum-average length of quotes (either in words, or in characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of quote: 256\n",
      "Minimum length of quote: 6\n",
      "Average length of quote: 121.49\n"
     ]
    }
   ],
   "source": [
    "quotes = train.quote\n",
    "len_of_quote = [len(i) for i in quotes]\n",
    "print('Maximum length of quote:', max(len_of_quote))\n",
    "print('Minimum length of quote:', min(len_of_quote))\n",
    "print('Average length of quote:', round(sum(len_of_quote)/len(len_of_quote), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how many reviews are in data multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 386\n"
     ]
    }
   ],
   "source": [
    "print('Number of duplicates:', len(train[train.duplicated() == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some extra summary statistics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count          mean           std      min    median          max\n",
      "imdb  10753.0  1.559055e+05  1.669296e+05  13442.0  114113.0    1190539.0\n",
      "rtid  10753.0  6.038135e+07  1.878349e+08     11.0   13380.0  771031792.0\n"
     ]
    }
   ],
   "source": [
    "# Get other summary stats\n",
    "summary = train.describe().transpose()\n",
    "summary.columns = ['count','mean','std','min','25%','median','75%','max']\n",
    "summary = summary[['count','mean','std','min','median','max']]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Let's clean the by removing all the inconsistencies the table reveals. We have to ensure that the central variables: quote and fresh are not missing, and quote is not an empty string (or just contain spaces and such)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    # remove 'none' for fresh\n",
    "    df = df[df['fresh'] != 'none']\n",
    "    # remove missing quotes?\n",
    "    df = df[df.quote.str.len() > 0]\n",
    "    # remove duplicates\n",
    "    df.drop_duplicates(keep=False, inplace=True) \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = clean(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naïve Bayes\n",
    "It's time to get serious and implement the Naive Bayes classifier from scratch. But first things first:\n",
    "\n",
    "Convert the data (quotes) into bag-of-words. Now we don't want a BOW that contains counts of words in quotes, but just 1/0 (or true/- false) for the presence/non-presence of the words. Convert the count-based BOW into such a presence BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "Number of rows: 9984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initialize the vectorizer\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "# `fit` builds the vocabulary\n",
    "# transform your data into the BOW array\n",
    "vectorizer.fit(train_clean.quote)\n",
    "X = vectorizer.transform(train_clean.quote).toarray()\n",
    "words_list = list(vectorizer.get_feature_names())\n",
    "\n",
    "print(X, '\\n')\n",
    "print('Number of rows:', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the work data and target (i.e. the variable fresh) into training and validation chunks (80/20 or so). Later we also do cross-validation, but for now, a simple training/validation will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrain, val = train_test_split(train_clean, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready with the preparatory work and it's time to dive into the real thing. Let's implement Naive Bayes. Use only training data in the fitting below.\n",
    "\n",
    "Compute the unconditional (log) probability that the tomato is fresh/rotten, log Pr(F), and log Pr(R). These probabilities are based on the values of fresh variable but not on the words the quotes contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fresh    -0.487356\n",
       "rotten   -0.952561\n",
       "Name: fresh, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = vtrain['fresh'].value_counts(normalize=True)\n",
    "np.log(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word w, compute log Pr(w|F) and log Pr(w|R), the (log) probability that the word is present in a fresh/rotten review. These probabilities can easily be calculated from counts of how many times these words are present for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw probability:\n",
      "pr(w|f):\n",
      " [0.25       1.         0.71428571 ... 0.         0.66666667 0.        ] \n",
      "\n",
      "pr(w|r):\n",
      " [0.75       0.         0.28571429 ... 1.         0.33333333 1.        ] \n",
      "\n",
      "Log probabilities:\n",
      "log pr(w|f):\n",
      " [-1.38629436  0.         -0.33647224 ...        -inf -0.40546511\n",
      "        -inf] \n",
      "\n",
      "log pr(w|r):\n",
      " [-0.28768207        -inf -1.25276297 ...  0.         -1.09861229\n",
      "  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yasmine\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Yasmine\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "pr_fr = vtrain.fresh.value_counts(normalize=True)\n",
    "pr_f, pr_r = np.log(pr_fr)\n",
    "\n",
    "# get the indices that contain fresh or rotten\n",
    "boolean_fresh = [1 if i == 'fresh' else 0 for i in train_clean.fresh]\n",
    "fresh_indices = []\n",
    "rotten_indices = []\n",
    "\n",
    "for i, j in enumerate(boolean_fresh):\n",
    "    if j == 1:\n",
    "        fresh_indices.append(i)\n",
    "    else:\n",
    "        rotten_indices.append(i)\n",
    "        \n",
    "# probability of w|fresh\n",
    "pr_w_f = np.divide(X[np.array(fresh_indices),:].sum(axis = 0).astype(float),X.sum(axis = 0).astype(float))\n",
    "\n",
    "# probability of w|rotten\n",
    "pr_w_r = np.divide(X[np.array(rotten_indices),:].sum(axis = 0).astype(float),X.sum(axis = 0).astype(float))\n",
    "\n",
    "print('Raw probability:')\n",
    "print('pr(w|f):\\n', pr_w_f, '\\n')\n",
    "print(\"pr(w|r):\\n\", pr_w_r, '\\n')\n",
    "\n",
    "\n",
    "# take the log of probability\n",
    "pr_w_f = np.log(pr_w_f)\n",
    "pr_w_r = np.log(pr_w_r)\n",
    "print('Log probabilities:')\n",
    "print('log pr(w|f):\\n', pr_w_f, '\\n')\n",
    "print('log pr(w|r):\\n', pr_w_r, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done with the estimator. Our fitted model is completely described by these four probability vectors: log Pr(F), log Pr(R), log Pr(w|F), log Pr(w|R). Let's now turn to prediction, and pull out our validation data (not the test data!).\n",
    "\n",
    "For both destination classes, F and R, compute the log-likelihood that the quote belongs to this class. Log-likelihood is essentially:\n",
    "\n",
    "_li(c) = log Pr(c) + where c ∈ {F, R} is the class, i is the review, j indexes words, and wij is the j-th word of the review\n",
    "i._\n",
    "\n",
    "Computing these likelihoods involves sums of the previously computed probabilities, log Pr(w|F), and BOW elements xij. \n",
    "\n",
    "Based on the log-likelihoods, predict the class F or R for each quote in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(quote):\n",
    "    words = quote.split(' ')\n",
    "    word_idx = []\n",
    "    for i in words:\n",
    "        if i in words_list:\n",
    "            word_idx.append(words_list.index(i))\n",
    "    tmp_p_f = pr_f\n",
    "    tmp_p_r = pr_r\n",
    "\n",
    "    if len(word_idx)>0:\n",
    "        tmp_p_f += np.sum(pr_w_f[np.array(word_idx)])\n",
    "        tmp_p_r += pr_r + np.sum(pr_w_r[np.array(word_idx)])\n",
    "    \n",
    "    if tmp_p_f > tmp_p_r:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# use vtrain to predict\n",
    "predicted = vtrain.quote.apply(predict).to_frame().quote\n",
    "predicted = list(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the resulting confusion matrix and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 81.59509202453987\n",
      "Confusion Matrix:\n",
      "[[1611 1470]\n",
      " [   0 4906]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y = [1 if i == 'fresh' else 0 for i in vtrain.fresh]\n",
    "output = [a == p for a,p in zip(predicted,y)]\n",
    "accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "matrix = confusion_matrix(y, predicted)\n",
    "print('Accuracy of the model:', accuracy)\n",
    "print('Confusion Matrix:')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interpretation\n",
    "Now it is time to look at our fitted model a little bit closer. NB model probabilities are rather easy to understand and interpret. The task here is to find the best words to predict a fresh, and a rotten review. And we only want to look at words that are reasonably frequent, say more frequent than 30 times in the data.\n",
    "\n",
    "1) Extract from the conditional probability vectors log Pr(F) and log Pr(R) the probabilities that correspond to frequent words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_X = X[np.array(fresh_indices),:]\n",
    "fresh_freq_idx = [i for (i,j) in enumerate(list(fresh_X.sum(axis = 0) >30)) if j == True]\n",
    "\n",
    "rotten_X = X[np.array(rotten_indices),:]\n",
    "rotten_freq_idx = [i for (i,j) in enumerate(list(rotten_X.sum(axis = 0) >30)) if j == True]\n",
    "\n",
    "# log probability vectors of frequent words\n",
    "top_p_f = pr_w_f[np.array(fresh_freq_idx)]\n",
    "top_p_r = pr_w_r[np.array(rotten_freq_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Find 10 best words to predict F and 10 best words to predict R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top fresh words:\n",
      " ['mumford', 'chafing', 'cesare', 'munro', 'cesar', 'murderer', 'certifiably', 'murkiness', 'murnau', 'largest']\n",
      "Top rotten words:\n",
      " ['kinkiness', 'kidnapping', 'kidron', 'kiel', 'killings', 'kin', 'kinberg', 'kinder', 'staginess', 'zzzzzzzzz']\n"
     ]
    }
   ],
   "source": [
    "top_f_idx = np.argsort(pr_w_f)[-10:]\n",
    "top_r_idx = np.argsort(pr_w_r)[-10:]\n",
    "\n",
    "top_f_words = [words_list[i] for i in top_f_idx]\n",
    "top_r_words = [words_list[i] for i in top_r_idx]\n",
    "\n",
    "print('Top fresh words:\\n', top_f_words)\n",
    "print('Top rotten words:\\n', top_r_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the top 10 words for fresh and rotten. For fresh, the top word is *mumford* and for rotten, the top word is *kinkiness*. We see some strange words, as described in the next prompt. This is because as mentioned above, when we have a review that contains just a single word, that word gains a lot of the weight. If a word also only appears once in the whole set, it will likely be classified as the only thing it was ever classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Print out a few missclassified quotes. Can we understand why these are misclassified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words from our top words, such as 'chafing,' 'mumford,' or 'zzzzzzzzz' appear to be misclassified because they do not really have any influence of the review really being \"fresh.\"\n",
    "\n",
    "We can probably attribute these words being misclassified becuase of the possibility that the words only appear once in the quotes. A review with only one word would also give that word a lot of weight in the model. This would mean that the BOW gives 100% or 0% probability of that word being what it was only classified as or has more weight from, hence some strange words coming into our top 10 \"fresh\" and \"rotten\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NB with smoothing\n",
    "Now we have our brand-new NB algorithm up and running. As a next step, we add smoothing to it. As we will be doing cross-validation below, our first task is to mold what we did above into two funcions: one for fitting and another one for predicting.\n",
    "\n",
    "1) Create two functions: one for fitting NB model, and another to predict outcome based on the fitted model.\n",
    "\n",
    "As mentioned above, the model is fully described with 4 probabilities, so the fitting function may return such a list as the model; and the prediction function may take it as an input.\n",
    "\n",
    "2) Add smoothing to the model. Smoothing amounts to assuming that we have seen every possible work α 0 times already, for both classes. (You can also assume you have seen the words α times for F and β times for R). Note that α does not have to be an integer, and typically the best α < 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fitNB(X_train, y_train, alpha):\n",
    "    global p_fresh, p_rotten, l_p_f, l_p_r, words_list\n",
    "    \n",
    "    # initialize the vectorizer\n",
    "    vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "    # create the dictionary\n",
    "    vectorizer.fit(X_train)\n",
    "\n",
    "    # `fit` builds the vocabulary\n",
    "    # transform your data into the BOW array\n",
    "    X = vectorizer.transform(X_train).toarray()\n",
    "    words_list = list(vectorizer.get_feature_names())\n",
    "\n",
    "    n_fresh = np.sum(y_train == 'fresh') + alpha\n",
    "    n_rotten = np.sum(y_train == 'rotten') + alpha\n",
    "    n_total = n_fresh + n_rotten\n",
    "    p_fresh = float(n_fresh) / float(n_total)\n",
    "    p_rotten = float(n_rotten) / float(n_total)\n",
    "    f_counts = X[y_train == 'fresh'].sum(axis = 0) + alpha\n",
    "    r_counts = X[y_train == 'rotten'].sum(axis = 0) + alpha\n",
    "    l_p_f = np.log(f_counts / n_fresh)\n",
    "    l_p_r = np.log(r_counts / n_rotten)\n",
    "    return p_fresh, p_rotten, l_p_f, l_p_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(quote):\n",
    "    words = quote.split(' ')\n",
    "    word_idx = []\n",
    "    for i in words:\n",
    "        if i in words_list:\n",
    "            word_idx.append(words_list.index(i))\n",
    "    tmp_p_f = p_fresh\n",
    "    tmp_p_r = p_rotten\n",
    "    \n",
    "    if len(word_idx)>0:\n",
    "        tmp_p_f += np.sum(l_p_f[np.array(word_idx)])\n",
    "        tmp_p_r += pr_r + np.sum(l_p_r[np.array(word_idx)])\n",
    "    \n",
    "    # if prob of fresh is greater than prob of rotten\n",
    "    if tmp_p_f > tmp_p_r:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Fit a few models with different α-s and see if the accuracy improves compared to the baseline case above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yasmine\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Yasmine\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0\n",
      "Accuracy of the model: 65.7486229344016\n",
      "Alpha: 0.1\n",
      "Accuracy of the model: 70.85628442663996\n",
      "Alpha: 0.2\n",
      "Accuracy of the model: 71.65748622934402\n",
      "Alpha: 0.3\n",
      "Accuracy of the model: 72.15823735603405\n",
      "Alpha: 0.4\n",
      "Accuracy of the model: 72.15823735603405\n",
      "Alpha: 0.5\n",
      "Accuracy of the model: 72.30846269404107\n",
      "Alpha: 0.6\n",
      "Accuracy of the model: 72.15823735603405\n",
      "Alpha: 0.7\n",
      "Accuracy of the model: 72.45868803204807\n",
      "Alpha: 0.8\n",
      "Accuracy of the model: 72.45868803204807\n",
      "Alpha: 0.9\n",
      "Accuracy of the model: 72.40861291937907\n",
      "Alpha: 1\n",
      "Accuracy of the model: 72.50876314471708\n"
     ]
    }
   ],
   "source": [
    "X_quote = vtrain.quote\n",
    "y = vtrain.fresh\n",
    "\n",
    "y_output = val.fresh\n",
    "y_output = [1 if i == 'fresh' else 0 for i in y_output]\n",
    "\n",
    "for al in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "    fitNB(X_quote, y, al)\n",
    "    predicted = val.quote.apply(predictNB).to_frame().quote\n",
    "    predicted = list(predicted)\n",
    "    # finding accuracy\n",
    "    output = [a == p for a,p in zip(predicted,y_output)]\n",
    "    accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "    print('Alpha:', al)\n",
    "    print('Accuracy of the model:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation\n",
    "Finally, we do cross-validation. Let's implement this ourself and not use existing libraries.\n",
    "\n",
    "- Implement k-fold CV as a function that a) puts the data into random order; b) splits these into k chunks; c) selects a chunk for testing and the others for training; d) trains your NB model on the training chunks; e) computes accuracy on training chunk; f) returns mean accuracy over all these k trials. The function should also take α as an argument, this is the hyperparameter you are going to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_frame(df, num_chunks): \n",
    "    listOfDf = list()\n",
    "    chunk_size = len(df) // num_chunks\n",
    "    for i in range(num_chunks):\n",
    "        listOfDf.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return listOfDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(data, k, alpha):\n",
    "    print('Number of chunks:', k)\n",
    "    print('Alpha:', alpha)\n",
    "    \n",
    "    chunks = split_data_frame(data, k)\n",
    "    accuracy_list = []\n",
    "    for chunk_df in chunks:\n",
    "        tmp_train = data[~data.isin(chunk_df)]\n",
    "        X_quote = tmp_train.quote.astype(str)\n",
    "        y = tmp_train.fresh\n",
    "\n",
    "        y_output = chunk_df.fresh\n",
    "        y_output = [1 if i == 'fresh' else 0 for i in y_output]\n",
    "\n",
    "        fitNB(X_quote, y, alpha)\n",
    "        predicted = chunk_df.quote.apply(predictNB).to_frame().quote\n",
    "        predicted = list(predicted)\n",
    "\n",
    "        # finding accuracy\n",
    "        output = [a == p for a,p in zip(predicted,y_output)]\n",
    "        accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "        accuracy_list.append(accuracy)\n",
    "       \n",
    "        print('Accuracy:', accuracy)\n",
    "    print('Average accuracy:', np.mean(accuracy_list))\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the optimal α by 5-fold CV using your own CV code. Find the cross-validated accuracies for a number of α-s between 0 and 1. Present the accuracy as a function of α on a plot and indicate which one is the best α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5\n",
      "Alpha: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yasmine\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Yasmine\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.98597194388778\n",
      "Accuracy: 67.08416833667334\n",
      "Accuracy: 65.03006012024048\n",
      "Accuracy: 66.18236472945893\n",
      "Accuracy: 66.38276553106212\n",
      "Average accuracy: 66.53306613226452\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.1\n",
      "Accuracy: 71.29258517034069\n",
      "Accuracy: 72.29458917835672\n",
      "Accuracy: 69.83967935871743\n",
      "Accuracy: 69.73947895791584\n",
      "Accuracy: 70.49098196392785\n",
      "Average accuracy: 70.7314629258517\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.2\n",
      "Accuracy: 72.24448897795591\n",
      "Accuracy: 72.59519038076152\n",
      "Accuracy: 69.93987975951904\n",
      "Accuracy: 70.29058116232466\n",
      "Accuracy: 70.79158316633266\n",
      "Average accuracy: 71.17234468937876\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.3\n",
      "Accuracy: 72.89579158316634\n",
      "Accuracy: 72.94589178356713\n",
      "Accuracy: 70.44088176352705\n",
      "Accuracy: 70.19038076152304\n",
      "Accuracy: 71.14228456913828\n",
      "Average accuracy: 71.52304609218437\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.4\n",
      "Accuracy: 72.84569138276554\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 70.74148296593187\n",
      "Accuracy: 70.39078156312625\n",
      "Accuracy: 71.09218436873748\n",
      "Average accuracy: 71.62324649298598\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.5\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 73.24649298597194\n",
      "Accuracy: 70.84168336673346\n",
      "Accuracy: 70.64128256513025\n",
      "Accuracy: 71.29258517034069\n",
      "Average accuracy: 71.81362725450902\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.6\n",
      "Accuracy: 73.29659318637275\n",
      "Accuracy: 73.49699398797596\n",
      "Accuracy: 71.09218436873748\n",
      "Accuracy: 71.04208416833667\n",
      "Accuracy: 71.59318637274549\n",
      "Average accuracy: 72.10420841683367\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.7\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 73.39679358717434\n",
      "Accuracy: 71.34268537074149\n",
      "Accuracy: 71.24248496993988\n",
      "Accuracy: 71.4929859719439\n",
      "Average accuracy: 72.10420841683367\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.8\n",
      "Accuracy: 73.19639278557113\n",
      "Accuracy: 73.24649298597194\n",
      "Accuracy: 71.34268537074149\n",
      "Accuracy: 71.34268537074149\n",
      "Accuracy: 71.44288577154309\n",
      "Average accuracy: 72.11422845691382\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 0.9\n",
      "Accuracy: 73.14629258517033\n",
      "Accuracy: 73.04609218436873\n",
      "Accuracy: 71.39278557114228\n",
      "Accuracy: 71.19238476953907\n",
      "Accuracy: 71.5430861723447\n",
      "Average accuracy: 72.06412825651303\n",
      "------\n",
      "Number of chunks: 5\n",
      "Alpha: 1\n",
      "Accuracy: 73.29659318637275\n",
      "Accuracy: 72.99599198396794\n",
      "Accuracy: 71.59318637274549\n",
      "Accuracy: 70.99198396793587\n",
      "Accuracy: 71.7434869739479\n",
      "Average accuracy: 72.12424849699399\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "    cross_val(train_clean, 5, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "acc = [66.53, 70.73, 71.17, 71.52, 71.62, 71.81, 72.10, 72.10, 72.11, 72.06, 72.12]\n",
    "\n",
    "plt.plot(alpha, acc, c = 'red')\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"average accuracy(%)\")\n",
    "plt.title(\"Alpha vs Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final model performance\n",
    "Finally, estimate the model performance on the testing data. Don't improve model after you have loaded testing data!\n",
    "\n",
    "1) Fit the NB model using the cross-validated optimal alpha using the complete work data (both training and validation). This is the best and final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6156619266973763,\n",
       " 0.38433807330262365,\n",
       " array([-8.03073492, -8.03073492, -6.93212264, ..., -8.7238821 ,\n",
       "        -7.62526982, -8.7238821 ]),\n",
       " array([-6.64326876, -8.25270668, -7.15409439, ..., -7.5595595 ,\n",
       "        -7.5595595 , -7.5595595 ]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal alpha: 1.0\n",
    "fitNB(train_clean.quote, train_clean.fresh, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Load the testing data. Clean it using exactly the same procedure and transform it into BOW-s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_clean = clean(test_df)\n",
    "\n",
    "y_output = test_clean.fresh\n",
    "y_output = [1 if i == 'fresh' else 0 for i in y_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Predict the F/R class on testing data. Compute accuracy. Present it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.85736021300875\n"
     ]
    }
   ],
   "source": [
    "predicted = test_clean.quote.apply(predictNB).to_frame().quote\n",
    "predicted = list(predicted)\n",
    "\n",
    "output = [a == p for a,p in zip(predicted,y_output)]\n",
    "accuracy = float(np.sum(output))/ float(len(output)) * 100\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Did we get a better or worse result compared to the k-NN and TF-IDF in PS04?\n",
    "\n",
    "We got about the same accuracy (~75%) as the k-NN and TF_IDF in PS04 (for k = 5). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
