{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO371 Problem set 4: k-NN, TF-IDF\n",
    "### Yasmine Hejazi\n",
    "Deadline: Tue, Feb 25th midnight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is the firstrst homework where you have to implement yourself some of the common ML algorithms. In\n",
    "particular, you will program k-NN with cosine similarity, using both bag-of-words and TF-IDF approach.\n",
    "\n",
    "Before you start, ensure you have read:\n",
    "\n",
    "- Daume \"A course in machine learning\", Ch 3.1 - 3.3. This a good introduction to k-NN.\n",
    "\n",
    "- my lecture notes, titled machineLearning, the chapter about k-NN. This includes metric distance, cosine distance, and TF-IDF. Feel free to give some feedback so I can improve on what is unclear. (The currect version is a quick hack.)\n",
    "\n",
    "You will use two types of data: first, various texts from Cantenbury corpus with several books added from\n",
    "Project Gutenberg, and thereafter Rotten Tomatoes, brief movie reviews. In case of the texts, your task\n",
    "is to find the correct source of the text, in case of tomatoes, to predict if the review is for a \"rotten\" or\n",
    "\"fresh\" movie.\n",
    "\n",
    "There is also a separate file with some example python code where you can find chunks of useful code\n",
    "for this problemset.\n",
    "\n",
    "Please submit a) your code (notebooks, rmd, whatever) and b) the lab in a final output form (html or\n",
    "pdf). Unlike PS1, you are free to choose either R or python for solving this problem set.\n",
    "While some of the intermediate output may be informative, please don't include too many lines of it\n",
    "in your solutions!\n",
    "\n",
    "Note: it includes questions you may want to answer on paper instead of computer. You are welcome\n",
    "to do it but please include the result as an image into your final file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Where are these texts coming from?\n",
    "\n",
    "The data file texts.csv contains the texts you have to classify. It contains the following variables:\n",
    "\n",
    "- **name**: name of the original file. It is usually author-name form and it should be fairly easy to find the\n",
    "original text in most cases.\n",
    "- **size**: size of the original text, in bytes\n",
    "- **lines**: size of the original text, in lines\n",
    "- **chunkid**: chunk id, from 1 and growing, see chunk. If you want to re-assemble the original texts, you just have to put these next to each other in the order of chunkid.\n",
    "- **chunk**: a page of text. It is not really a page, just 25 lines of text, whatever happened to be on those 25\n",
    "lines.\n",
    "\n",
    "Text chunks are just verbatim texts that may contain all kind of characters, including newlines. Note the\n",
    "file is tab separated and uses quotes for strings.\n",
    "\n",
    "Your task is to read all the texts, convert these to a) bag-of-words, and b) TF-IDF-s, and predict the\n",
    "correct source using k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bag of words\n",
    "\n",
    "First, let's use bag-of-words (BOW) approach.\n",
    "\n",
    "1. Load the data. Print out a few lines of it to inspect it's structure.\n",
    "2. Inspect some of the texts. Note that chunkid 1 corresponds to the first page of the text.\n",
    "3. List all the text sources listed in variable name. How many different texts does the data contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>lines</th>\n",
       "      <th>chunkid</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nTitle: Early Lives of Charlemagne by Eginhar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\nThe notes, keyed to line numbers in the so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n         From a bronze statuette in the Musé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n                _A lui finit la dissolution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>5</td>\n",
       "      <td>public opinion in regard to the meaning of fal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name    size  lines  chunkid  \\\n",
       "0  balbulus-early-life-charlemagne  259062   4394        1   \n",
       "1  balbulus-early-life-charlemagne  259062   4394        2   \n",
       "2  balbulus-early-life-charlemagne  259062   4394        3   \n",
       "3  balbulus-early-life-charlemagne  259062   4394        4   \n",
       "4  balbulus-early-life-charlemagne  259062   4394        5   \n",
       "\n",
       "                                               chunk  \n",
       "0  \\nTitle: Early Lives of Charlemagne by Eginhar...  \n",
       "1  \\n\\nThe notes, keyed to line numbers in the so...  \n",
       "2  \\n         From a bronze statuette in the Musé...  \n",
       "3  \\n                _A lui finit la dissolution ...  \n",
       "4  public opinion in regard to the meaning of fal...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_csv(\"texts.csv\", sep='\\t')\n",
    "# note: as the texts may contain various symbols, including tabs and commas,\n",
    "# you may to have specify 'sep' and maybe other extra arguments\n",
    "\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 12924\n",
      "Number of titles: 29\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of texts: %i\" % texts.shape[0])\n",
    "print(\"Number of titles: %i\" % len(np.unique(texts.name.astype('str'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ALICE'S ADVENTURES IN WONDERLAND\n",
      "\n",
      "                          Lewis Carroll\n",
      "\n",
      "               THE MILLENNIUM FULCRUM EDITION 2.9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            CHAPTER I\n",
      "\n",
      "                      Down the Rabbit-Hole\n",
      "\n",
      "\n",
      "  Alice was beginning to get very tired of sitting by her sister\n",
      "on the bank, and of having nothing to do:  once or twice she had\n",
      "peeped into the book her sister was reading, but it had no\n",
      "pictures or conversations in it, `and what is the use of a book,'\n",
      "thought Alice `without pictures or conversation?'\n",
      "\n",
      "  So she was considering in her own mind (as well as she could,\n",
      "for the hot day made her feel very sleepy and stupid), whether\n",
      "the pleasure of making a daisy-chain would be worth the trouble\n"
     ]
    }
   ],
   "source": [
    "first_pages = texts[texts['chunkid'] == 1]\n",
    "first_pages\n",
    "\n",
    "# inspect alice in wonderland\n",
    "print(first_pages[first_pages['name'] == 'carroll-alice-wonderland'].chunk.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text sources:  ['balbulus-early-life-charlemagne' 'beesly-queen-elizabeth' 'bible'\n",
      " 'carroll-alice-wonderland' 'chipman-earliest-electromagnetic-instruments'\n",
      " 'cia-world-factbook-1992' 'eckstein-quintus-claudius'\n",
      " 'fisher-quaker-colonies' 'gallienne-quest-of-golden-girl'\n",
      " 'gordon-quiet-talks-crowned-christ' 'hardy-madding-crowd'\n",
      " 'infiltrating-open-systems' 'kant-metaphysical-elements-ethics'\n",
      " 'karn-snowflakes' 'milton-paradise-lost'\n",
      " 'naval-academy-sound-military-decision' 'newsgroup'\n",
      " 'paper-compact-hash-tables' 'paper-data-compression'\n",
      " 'paper-logical-implementation-of-arithmetic'\n",
      " 'paper-programming-by-example' 'paper-search-for-autonomy'\n",
      " 'selected-polish-tales' 'shakespeare-as-you-like-it'\n",
      " 'unamuno-tragic-sense-of-life' 'vaneeden-quest'\n",
      " 'webster-early-european-history' 'why-speech-output'\n",
      " 'workshop-proceedings'] \n",
      "\n",
      "Number of text sources:  29\n"
     ]
    }
   ],
   "source": [
    "print(\"All text sources: \", np.unique(texts.name), \"\\n\")\n",
    "print(\"Number of text sources: \", len(np.unique(texts.name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you feel you know the data well enough, it's time to split it into testing and validating parts.\n",
    "\n",
    "**Warning**: start slow. The dataset contains 13,000 texts and 65,000 unique words. If you load in\n",
    "everything, the BOW matrix takes approximately 8GB of RAM. I recommend to start with very small\n",
    "datasets, say 10 pages for both training and validation. When your code works, start increasing the size.\n",
    "Stop where it gets too slow, you don't have to run everything (it takes 18G RAM). But note that if you\n",
    "drastically scale down the amount of data, you should also select only a few sources. Otherwise you may\n",
    "have no examples from certain sources to compare to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you have created your training and testing sets, it is time to create the dictionary. See the example code for python examples, there are many examples on the web about how to do it with R (see text mining with R or text2vec package). \n",
    "\n",
    "This process contains two steps: \n",
    "\n",
    "1) create a dictionary of all your texts. \n",
    "\n",
    "2) recode all the texts as BOW vector. See the lecture notes for explanation about BOW.\n",
    "\n",
    "Note you may want to feed in all your data, i.e. both training and validation data into the dictionary.\n",
    "This ensures all words in your validation are represented in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "ntrain = 40\n",
    "nVal = 10\n",
    "\n",
    "train = texts.sample(n=ntrain,random_state = 1)\n",
    "val = texts.loc[~texts.index.isin(train_df)].sample(n=nVal,random_state = 1)\n",
    "\n",
    "# split intro train/val\n",
    "X_train = train.chunk\n",
    "X_val = val.chunk\n",
    "y_train = train.name\n",
    "y_val = val.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]] \n",
      "\n",
      "Number of rows: 50\n"
     ]
    }
   ],
   "source": [
    "# for simplicity, I recommend to create dictionary based on the\n",
    "# merged training and validation data\n",
    "sentences = np.concatenate((X_train.values, X_val.values),axis=0)\n",
    "\n",
    "## initialize the vectorizer\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "## create the dictionary\n",
    "vectorizer.fit(sentences)\n",
    "# `fit` builds the vocabulary\n",
    "## transform your data into the BOW array\n",
    "X = vectorizer.transform(sentences).toarray()\n",
    "\n",
    "print(X, '\\n')\n",
    "print('Number of rows:', len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have all your (training and validation) texts in BOW form. This is great, we just transformed texts into (numeric) vectors! Now implement cosine similarity between these vectors.\n",
    "\n",
    "Ensure you have read the lecture notes about cosine similarity. Write a function that takes in two\n",
    "vectors, x and y, and returns the corresponding cosine similarity c(x,y). Test if c(x, x) = 1, test\n",
    "also a few other vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according to the definition of the dot product\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "cos_sim(X[1], X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, implement k-NN. I mean implement it yourself, don't use pre-existing libraries. I recommend\n",
    "to do 1-NN first, and when this works to extend it to k-NN. You need an algorithm along these lines:\n",
    "    \n",
    "(a) Pick a validation case y (later you will loop over all of these).\n",
    "\n",
    "(b) for each vector in the training set xi, compute the cosine similarity c(y, xi). Store this number,\n",
    "and ensure you know which xi corresponds to each c value.\n",
    "\n",
    "(c) Now order all the cosine similarities you just computed in an increasing order.\n",
    "\n",
    "(d) Pick the k highest c-s. These correspond to your k nearest neighbors! Ensure you know which\n",
    "texts these are.\n",
    "\n",
    "Now you know your nearest neighbors. Organize a majority voting among them so you will learn which text is the most popular among them. I recommend to create a frequency table and pick the most common text source name based on this.\n",
    "\n",
    "Compute accuracy (percentage of correct predictions). How good is your algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: webster-early-european-history\n",
      "Correct: webster-early-european-history\n"
     ]
    }
   ],
   "source": [
    "y = X[-1]\n",
    "train_cases = X[:40]\n",
    "result = []\n",
    "correct = []\n",
    "\n",
    "for i,j in enumerate(train_cases):\n",
    "    result.append((i, cos_sim(y, j)))\n",
    "    \n",
    "ordered_result = sorted(result, key=lambda tup: tup[1], reverse=True)  \n",
    "\n",
    "print(\"Predicted:\", train.iloc[ordered_result[0][0], 0])\n",
    "print(\"Correct:\", val.iloc[9, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get accuracy of predicted responses\n",
    "def accuracy(responses):\n",
    "    return float(sum(i == 1 for i in responses)) / float(len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = 1000\n",
    "nVal = 100\n",
    "\n",
    "train = texts.sample(n=ntrain,random_state = 123)\n",
    "val = texts.loc[~texts.index.isin(train)].sample(n=nVal,random_state = 123)\n",
    "\n",
    "X_train = train.chunk\n",
    "X_val = val.chunk\n",
    "y_train = train.name\n",
    "y_val = val.name\n",
    "\n",
    "sentences = np.concatenate((X_train.values, X_val.values),axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "vectorizer.fit(sentences)\n",
    "X = vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_cases = X[:ntrain]\n",
    "correct = []\n",
    "\n",
    "for i in range(ntrain, ntrain + nVal):\n",
    "    val_case = X[i]\n",
    "    result = []\n",
    "    \n",
    "    for j,k in enumerate(train_cases):\n",
    "        result.append((j, cos_sim(k, val_case)))\n",
    "        \n",
    "    ordered_result = sorted(result, key=lambda tup: tup[1], reverse=True)    \n",
    "    # add 1 if prediction is correct\n",
    "    if train.iloc[ordered_result[0][0], 0] == val.iloc[i-1000, 0]:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)\n",
    "    \n",
    "\n",
    "print(\"Accuracy:\", accuracy(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tried this, let's look into other values for k!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k):\n",
    "    print(\"k:\", k)\n",
    "    correct = []\n",
    "    \n",
    "    for i in range(ntrain, ntrain + nVal):\n",
    "        val_case = X[i]\n",
    "        result = []\n",
    "        \n",
    "        for j, m in enumerate(train_cases):\n",
    "            result.append((j, cos_sim(m, val_case)))\n",
    "            \n",
    "        ordered_result = sorted(result, key=lambda tup: tup[1],reverse=True)[:k]\n",
    "        vals = [y_train.iloc[o[0]] for o in ordered_result]\n",
    "        most_common = max(map(lambda val: (vals.count(val), val), set(vals)))[1]\n",
    "        \n",
    "        if str(most_common) == y_val.iloc[i-ntrain]:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    print(\"Accuracy:\", accuracy(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Load the data. Inspect it a little bit to see how it is coded and organized. How many cases do you have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 9.062533855438232\n",
      "k: 5\n",
      "Accuracy: 0.64\n",
      "Time elapsed: 9.342237949371338\n",
      "k: 25\n",
      "Accuracy: 0.44\n",
      "Time elapsed: 9.526848077774048\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for l in [1,5,25]:\n",
    "    start = time.time()\n",
    "    knn(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model is when **k = 1** with an accuracy of 1.0. Accuracy decreases as we increase k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 TF-IDF\n",
    "\n",
    "BOW is great but could be even greater. Can we get a better result using TF-IDF? TF-IDF is simply a way how to weigh the word frequency in a more informative way.\n",
    "\n",
    "1. Implement TF-IDF transformation. Note: implement it yourself, don't rely on existing libraries! This involves manipulating your training and validation data matrices, nothing else needs to be done. Example will be given in the notes.\n",
    "2. Now ensure that your cosine similarity you implemented earlier also works for vectors in TF-IDF form. It should, without any modi􏰄cations, if you implemented in well.\n",
    "3. Run your k-NN with cosine similarity algorithm again, using several k values, like 1,5,25. The algorithm should not need any modi􏰄cations.\n",
    "4. Finally, comment your results. How accurate is BOW versus TF-IDF? How does choice of k change the results? Is BOW or TF-IDF faster to run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_tfidf(k):\n",
    "    print(\"k:\", k)\n",
    "    correct = []\n",
    "    for i in range(ntrain, ntrain + nVal):\n",
    "        val_case = tfidf[i]\n",
    "        result = []\n",
    "        \n",
    "        for j, m in enumerate(train_tfidf):\n",
    "            result.append((j, cos_sim(m, val_case)))\n",
    "            \n",
    "        ordered_result = sorted(result, key=lambda tup: tup[1], reverse=True)[:k]\n",
    "        vals = [y_train.iloc[o[0]] for o in ordered_result]\n",
    "        most_common = max(map(lambda val: (vals.count(val), val), set(vals)))[1]\n",
    "        \n",
    "        if str(most_common) == y_val.iloc[i-ntrain]:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "            \n",
    "    print(\"Accuracy:\", accuracy(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19029, 1100)\n",
      "(1100, 1100)\n",
      "(1100, 19029)\n",
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 84.35733389854431\n",
      "k: 5\n",
      "Accuracy: 0.64\n",
      "Time elapsed: 79.55618381500244\n",
      "k: 25\n",
      "Accuracy: 0.44\n",
      "Time elapsed: 85.2572090625763\n"
     ]
    }
   ],
   "source": [
    "tf = X.T #term frequency\n",
    "\n",
    "idf = np.log(tf.shape[1] / ( 1 + sum(tf != 0) ))\n",
    "idf = np.diag(idf)\n",
    "\n",
    "tfidf = np.dot(tf,idf).T\n",
    "\n",
    "print(tf.shape)\n",
    "print(idf.shape)\n",
    "print(tfidf.shape, '\\n')\n",
    "\n",
    "# normalize\n",
    "tfidf = tfidf/np.sqrt(np.sum(tfidf**22))\n",
    "\n",
    "# train datasets\n",
    "train_tfidf = tfidf[:ntrain]\n",
    "\n",
    "for l in [1, 5, 25]:\n",
    "    start = time.time()\n",
    "    knn_tfidf(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How accurate is BOW versus TF-IDF? How does choice of k change the results? Is BOW or TF-IDF faster to run?*\n",
    "\n",
    "Accuracy appears to be the same for both models when k = 1, 5, and 25. The change in the choice of k remains to have the same pattern, where accuracy decreases as k increases. BOW is much faster to run than TD-IDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Are tomatoes fresh or rotten?\n",
    "\n",
    "Our next task is to use your freshly minted methods for classifying the Rotten Tomatoes movie reviews. Please familiarize yourself a little bit with the webpage. Brie􏰅y, approved critics can write reviews for movies, and evaluate the movie as 􏰀fresh􏰁 or 􏰀rotten􏰁. The webpage normally shows a short 􏰀quote􏰁 from each critic, and whether it was evaluated as fresh or rotten. You will work on these quotes below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the data. Inspect it a little bit to see how it is coded and organized. How many cases do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 13442\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/87745/toy-...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.newsweek.com/id/104199</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.variety.com/review/VE1117941294.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb  \\\n",
       "0         Derek Adams  fresh  114709   \n",
       "1     Richard Corliss  fresh  114709   \n",
       "2         David Ansen  fresh  114709   \n",
       "3       Leonard Klady  fresh  114709   \n",
       "4  Jonathan Rosenbaum  fresh  114709   \n",
       "\n",
       "                                                link     publication  \\\n",
       "0  http://www.timeout.com/film/reviews/87745/toy-...        Time Out   \n",
       "1  http://www.time.com/time/magazine/article/0,91...   TIME Magazine   \n",
       "2                  http://www.newsweek.com/id/104199        Newsweek   \n",
       "3  http://www.variety.com/review/VE1117941294.htm...         Variety   \n",
       "4  http://onfilm.chicagoreader.com/movies/capsule...  Chicago Reader   \n",
       "\n",
       "                                               quote          review_date  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04 00:00:00   \n",
       "1                  The year's most inventive comedy.  2008-08-31 00:00:00   \n",
       "2  A winning animated feature that has something ...  2008-08-18 00:00:00   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09 00:00:00   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10 00:00:00   \n",
       "\n",
       "   rtid      title  \n",
       "0  9559  Toy Story  \n",
       "1  9559  Toy Story  \n",
       "2  9559  Toy Story  \n",
       "3  9559  Toy Story  \n",
       "4  9559  Toy Story  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten = pd.read_csv(\"reviews.csv\")\n",
    "print(\"Number of cases:\", len(rotten))\n",
    "rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data. Retain only cases where fresh and quote are present and non-empty. Remove repeated observations (there are such in data). How many cases will be left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 12823\n"
     ]
    }
   ],
   "source": [
    "rotten = rotten[rotten.fresh != \"none\"]\n",
    "rotten = rotten.drop_duplicates()\n",
    "print(\"Number of cases:\", len(rotten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select training and validation data. You would like to split all cases into 80-20 groups. However, as before, this may be slow. Start slow with perhaps 100 random quotes split into two groups.\n",
    "\n",
    "Your task is to 􏰄nd the closest training quotes for each test quote, and based on those predict if the movie is fresh or rotten according to the quote.\n",
    "\n",
    "Follow the same steps you did with the texts above:\n",
    "\n",
    "(a) create dictionary and BOW of all quotes\n",
    "\n",
    "(b) run k-NN with several di􏰃erent k-s, and predict if fresh or rotten. In each time compute the accuracy.\n",
    "\n",
    "(c) transform your data into TF-IDF form and repeat k-NN.\n",
    "\n",
    "(d) inspect a few cases where the tomato was correctly/incorrectly predicted. Can you explain why\n",
    "the algorithm behaved in the way it behaved?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 1500\n",
    "nVal = 300\n",
    "\n",
    "train_df = rotten.sample(n=ntrain, random_state = 123)\n",
    "val_df = rotten.loc[~rotten.index.isin(train_df)].sample(n=nVal, random_state = 123)\n",
    "\n",
    "X_train = train_df.quote\n",
    "X_val = val_df.quote\n",
    "y_train = train_df.fresh\n",
    "y_val = val_df.fresh\n",
    "\n",
    "sentences = np.concatenate((X_train.values, X_val.values),axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "vectorizer.fit(sentences)\n",
    "X = vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created dictionary and BOW of all quotes, run k-NN with several di􏰃erent k-s, and predict if fresh or rotten. In each time compute the accuracy.\n",
    "\n",
    "** Essentially, we are doing the same thing as what we did above!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 21.175053119659424\n",
      "k: 5\n",
      "Accuracy: 0.7533333333333333\n",
      "Time elapsed: 21.226906061172485\n",
      "k: 25\n",
      "Accuracy: 0.6866666666666666\n",
      "Time elapsed: 19.433835983276367\n"
     ]
    }
   ],
   "source": [
    "# BOW\n",
    "train_cases = X[:ntrain]\n",
    "\n",
    "for l in [1, 5, 25]:\n",
    "    start = time.time()\n",
    "    knn(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform your data into TF-IDF form and repeat k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 107.86344408988953\n",
      "k: 5\n",
      "Accuracy: 0.75\n",
      "Time elapsed: 104.58056592941284\n",
      "k: 25\n",
      "Accuracy: 0.6866666666666666\n",
      "Time elapsed: 108.30084800720215\n"
     ]
    }
   ],
   "source": [
    "# TD-IDF\n",
    "tf = X.T #term frequency\n",
    "\n",
    "idf = np.log(tf.shape[1] / ( 1 + sum(tf != 0) ))\n",
    "idf = np.diag(idf)\n",
    "\n",
    "tfidf = np.dot(tf,idf).T\n",
    "\n",
    "print(tf.shape)\n",
    "print(idf.shape)\n",
    "print(tfidf.shape, '\\n')\n",
    "\n",
    "# normalize\n",
    "tfidf = tfidf/np.sqrt(np.sum(tfidf**22))\n",
    "\n",
    "# train datasets\n",
    "train_tfidf = tfidf[:ntrain]\n",
    "\n",
    "for l in [1,5,25]:\n",
    "    start = time.time()\n",
    "    knn_tfidf(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, comment your results. What worked better: reviews or text pages? What worked better: BOW or TF-IDF*\n",
    "\n",
    "We can say once again that: both of our models are best when k = 1, with an accuracy of 1.0. Accuracy decreases as we increase k. BOW and TF-IDF seemed to have similar accuracies with the same k's again, just as we saw in the last section. When we compare reviews vs text pages, we see that with reviews, accuracy decreases along with k at a lesser rate than text pages, showing us that reviews may have worked better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
