{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO371 Problem set 4: k-NN, TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we will program k-NN with cosine similarity using both bag-of-words and TF-IDF approaches.\n",
    "\n",
    "We will use two types of data: first, various texts from Cantenbury corpus with several books added from\n",
    "Project Gutenberg, and thereafter Rotten Tomatoes, brief movie reviews. In case of the texts, we will find the correct source of the text. In case of tomatoes, to predict if the review is for a \"rotten\" or\"fresh\" movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Where are these texts coming from?\n",
    "\n",
    "The data file texts.csv contains the textswe need to classify. It contains the following variables:\n",
    "\n",
    "- **name**: name of the original file. It is usually author-name form and it should be fairly easy to find the\n",
    "original text in most cases.\n",
    "- **size**: size of the original text, in bytes\n",
    "- **lines**: size of the original text, in lines\n",
    "- **chunkid**: chunk id, from 1 and growing, see chunk. If you want to re-assemble the original texts, you just have to put these next to each other in the order of chunkid.\n",
    "- **chunk**: a page of text. It is not really a page, just 25 lines of text, whatever happened to be on those 25\n",
    "lines.\n",
    "\n",
    "Text chunks are just verbatim texts that may contain all kind of characters, including newlines. Note the\n",
    "file is tab separated and uses quotes for strings.\n",
    "\n",
    "We need to read all the texts, convert these to a) bag-of-words, and b) TF-IDF-s, and predict the\n",
    "correct source using k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bag of words\n",
    "\n",
    "First, let's use bag-of-words (BOW) approach.\n",
    "\n",
    "1. Load the data. Print out a few lines of it to inspect it's structure.\n",
    "2. Inspect some of the texts. Note that chunkid 1 corresponds to the first page of the text.\n",
    "3. List all the text sources listed in variable name. How many different texts does the data contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>lines</th>\n",
       "      <th>chunkid</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nTitle: Early Lives of Charlemagne by Eginh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>2</td>\n",
       "      <td>\\r\\n\\r\\nThe notes, keyed to line numbers in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>3</td>\n",
       "      <td>\\r\\n         From a bronze statuette in the Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>4</td>\n",
       "      <td>\\r\\n                _A lui finit la dissolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>259062</td>\n",
       "      <td>4394</td>\n",
       "      <td>5</td>\n",
       "      <td>public opinion in regard to the meaning of fal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name    size  lines  chunkid  \\\n",
       "0  balbulus-early-life-charlemagne  259062   4394        1   \n",
       "1  balbulus-early-life-charlemagne  259062   4394        2   \n",
       "2  balbulus-early-life-charlemagne  259062   4394        3   \n",
       "3  balbulus-early-life-charlemagne  259062   4394        4   \n",
       "4  balbulus-early-life-charlemagne  259062   4394        5   \n",
       "\n",
       "                                               chunk  \n",
       "0  \\r\\nTitle: Early Lives of Charlemagne by Eginh...  \n",
       "1  \\r\\n\\r\\nThe notes, keyed to line numbers in th...  \n",
       "2  \\r\\n         From a bronze statuette in the Mu...  \n",
       "3  \\r\\n                _A lui finit la dissolutio...  \n",
       "4  public opinion in regard to the meaning of fal...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_csv(\"texts.csv\", sep='\\t')\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 12924\n",
      "Number of titles: 29\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of texts: %i\" % texts.shape[0])\n",
    "print(\"Number of titles: %i\" % len(np.unique(texts.name.astype('str'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ALICE'S ADVENTURES IN WONDERLAND\r\n",
      "\r\n",
      "                          Lewis Carroll\r\n",
      "\r\n",
      "               THE MILLENNIUM FULCRUM EDITION 2.9\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "                            CHAPTER I\r\n",
      "\r\n",
      "                      Down the Rabbit-Hole\r\n",
      "\r\n",
      "\r\n",
      "  Alice was beginning to get very tired of sitting by her sister\r\n",
      "on the bank, and of having nothing to do:  once or twice she had\r\n",
      "peeped into the book her sister was reading, but it had no\r\n",
      "pictures or conversations in it, `and what is the use of a book,'\r\n",
      "thought Alice `without pictures or conversation?'\r\n",
      "\r\n",
      "  So she was considering in her own mind (as well as she could,\r\n",
      "for the hot day made her feel very sleepy and stupid), whether\r\n",
      "the pleasure of making a daisy-chain would be worth the trouble\n"
     ]
    }
   ],
   "source": [
    "first_pages = texts[texts['chunkid'] == 1]\n",
    "first_pages\n",
    "\n",
    "# inspect alice in wonderland\n",
    "print(first_pages[first_pages['name'] == 'carroll-alice-wonderland'].chunk.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text sources:  ['balbulus-early-life-charlemagne' 'beesly-queen-elizabeth' 'bible'\n",
      " 'carroll-alice-wonderland' 'chipman-earliest-electromagnetic-instruments'\n",
      " 'cia-world-factbook-1992' 'eckstein-quintus-claudius'\n",
      " 'fisher-quaker-colonies' 'gallienne-quest-of-golden-girl'\n",
      " 'gordon-quiet-talks-crowned-christ' 'hardy-madding-crowd'\n",
      " 'infiltrating-open-systems' 'kant-metaphysical-elements-ethics'\n",
      " 'karn-snowflakes' 'milton-paradise-lost'\n",
      " 'naval-academy-sound-military-decision' 'newsgroup'\n",
      " 'paper-compact-hash-tables' 'paper-data-compression'\n",
      " 'paper-logical-implementation-of-arithmetic'\n",
      " 'paper-programming-by-example' 'paper-search-for-autonomy'\n",
      " 'selected-polish-tales' 'shakespeare-as-you-like-it'\n",
      " 'unamuno-tragic-sense-of-life' 'vaneeden-quest'\n",
      " 'webster-early-european-history' 'why-speech-output'\n",
      " 'workshop-proceedings'] \n",
      "\n",
      "Number of text sources:  29\n"
     ]
    }
   ],
   "source": [
    "print(\"All text sources: \", np.unique(texts.name), \"\\n\")\n",
    "print(\"Number of text sources: \", len(np.unique(texts.name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to split it into testing and validating parts.\n",
    "\n",
    "**Warning**: The dataset contains 13,000 texts and 65,000 unique words. If you load in\n",
    "everything, the BOW matrix takes approximately 8GB of RAM. It is recommended to start with very small\n",
    "datasets, say 10 pages for both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "ntrain = 40\n",
    "nVal = 10\n",
    "\n",
    "train = texts.sample(n=ntrain, random_state=1)\n",
    "val = texts.loc[~texts.index.isin(train)].sample(n=nVal, random_state=1)\n",
    "\n",
    "# split intro train/val\n",
    "X_train = train.chunk\n",
    "X_val = val.chunk\n",
    "y_train = train.name\n",
    "y_val = val.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the training and testing sets, it is time to create the dictionary. This process contains two steps: \n",
    "\n",
    "1) Create a dictionary of all your texts. \n",
    "\n",
    "2) Recode all the texts as BOW vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "Number of rows: 50\n"
     ]
    }
   ],
   "source": [
    "sentences = np.concatenate((X_train.values, X_val.values),axis=0)\n",
    "\n",
    "# initialize the vectorizer\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "# create the dictionary\n",
    "vectorizer.fit(sentences) # `fit` builds the vocabulary\n",
    "\n",
    "# transform your data into the BOW array\n",
    "X = vectorizer.transform(sentences).toarray()\n",
    "\n",
    "print(X, '\\n')\n",
    "print('Number of rows:', len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all your (training and validation) texts in BOW form. This is great; we just transformed texts into (numeric) vectors! Now we need to implement cosine similarity between these vectors.\n",
    "\n",
    "We should write a function that takes in two vectors, x and y, and returns the corresponding cosine similarity c(x,y). Test if c(x, x) = 1, test, and also a few other vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according to the definition of the dot product\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "cos_sim(X[1], X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will implement k-NN (without using pre-existing libraries!). Let's first try 1-NN, and when this works, extend it to k-NN. The algorithm is something along these lines:\n",
    "    \n",
    "(a) Pick a validation case y (later we will loop over all of these).\n",
    "\n",
    "(b) For each vector in the training set xi, compute the cosine similarity c(y, xi). Store this number,\n",
    "and ensure we know which xi corresponds to each c value.\n",
    "\n",
    "(c) Now order all the cosine similarities we just computed in an increasing order.\n",
    "\n",
    "(d) Pick the k highest c-s. These correspond to our k nearest neighbors! Ensure we know which\n",
    "texts these are.\n",
    "\n",
    "Organize a majority voting among them to learn which text is the most popular among them. Create a frequency table and pick the most common text source name based on this. Then, compute accuracy (percentage of correct predictions). How good is your algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: webster-early-european-history\n",
      "Correct: webster-early-european-history\n"
     ]
    }
   ],
   "source": [
    "y = X[-1]\n",
    "train_cases = X[:40]\n",
    "result = []\n",
    "correct = []\n",
    "\n",
    "for i,j in enumerate(train_cases):\n",
    "    result.append((i, cos_sim(y, j)))\n",
    "    \n",
    "ordered_result = sorted(result, key=lambda tup: tup[1], reverse=True)  \n",
    "\n",
    "print(\"Predicted:\", train.iloc[ordered_result[0][0], 0])\n",
    "print(\"Correct:\", val.iloc[9, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy of predicted responses\n",
    "def accuracy(responses):\n",
    "    return float(sum(i == 1 for i in responses)) / float(len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 1000\n",
    "nVal = 100\n",
    "\n",
    "train = texts.sample(n=ntrain,random_state = 123)\n",
    "val = texts.loc[~texts.index.isin(train)].sample(n=nVal,random_state = 123)\n",
    "\n",
    "X_train = train.chunk\n",
    "X_val = val.chunk\n",
    "y_train = train.name\n",
    "y_val = val.name\n",
    "\n",
    "sentences = np.concatenate((X_train.values, X_val.values),axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "vectorizer.fit(sentences)\n",
    "X = vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_cases = X[:ntrain]\n",
    "correct = []\n",
    "\n",
    "for i in range(ntrain, ntrain + nVal):\n",
    "    val_case = X[i]\n",
    "    result = []\n",
    "    \n",
    "    for j,k in enumerate(train_cases):\n",
    "        result.append((j, cos_sim(k, val_case)))\n",
    "        \n",
    "    ordered_result = sorted(result, key=lambda tup: tup[1], reverse=True)    \n",
    "    # add 1 if prediction is correct\n",
    "    if train.iloc[ordered_result[0][0], 0] == val.iloc[i-1000, 0]:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)\n",
    "    \n",
    "\n",
    "print(\"Accuracy:\", accuracy(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tried this, let's look into other values for k!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k):\n",
    "    print(\"k:\", k)\n",
    "    correct = []\n",
    "    \n",
    "    for i in range(ntrain, ntrain + nVal):\n",
    "        val_case = X[i]\n",
    "        result = []\n",
    "        \n",
    "        for j, m in enumerate(train_cases):\n",
    "            result.append((j, cos_sim(m, val_case)))\n",
    "            \n",
    "        ordered_result = sorted(result, key=lambda tup: tup[1],reverse=True)[:k]\n",
    "        vals = [y_train.iloc[o[0]] for o in ordered_result]\n",
    "        most_common = max(map(lambda val: (vals.count(val), val), set(vals)))[1]\n",
    "        \n",
    "        if str(most_common) == y_val.iloc[i-ntrain]:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    print(\"Accuracy:\", accuracy(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 6.447309255599976\n",
      "k: 5\n",
      "Accuracy: 0.64\n",
      "Time elapsed: 6.572238445281982\n",
      "k: 25\n",
      "Accuracy: 0.44\n",
      "Time elapsed: 6.905047178268433\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for l in [1,5,25]:\n",
    "    start = time.time()\n",
    "    knn(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model is when **k = 1** with an accuracy of 1.0. Accuracy decreases as we increase k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 TF-IDF\n",
    "\n",
    "BOW is great but could be even greater. Can we get a better result using TF-IDF? TF-IDF is simply a way how to weigh the word frequency in a more informative way.\n",
    "\n",
    "1. Implement TF-IDF transformation (without rely on existing libraries!). This involves manipulating the training and validation data matrices, nothing else needs to be done.\n",
    "2. Ensure that the cosine similarity implemented earlier also works for vectors in TF-IDF form. It should without any modifcations.\n",
    "3. Run k-NN with the cosine similarity algorithm again, using several k values. The algorithm should not need any modifcations.\n",
    "4. How accurate is BOW versus TF-IDF? How does choice of k change the results? Is BOW or TF-IDF faster to run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_tfidf(k):\n",
    "    print(\"k:\", k)\n",
    "    correct = []\n",
    "    for i in range(ntrain, ntrain + nVal):\n",
    "        val_case = tfidf[i]\n",
    "        result = []\n",
    "        \n",
    "        for j, m in enumerate(train_tfidf):\n",
    "            result.append((j, cos_sim(m, val_case)))\n",
    "            \n",
    "        ordered_result = sorted(result, key=lambda tup: tup[1], reverse=True)[:k]\n",
    "        vals = [y_train.iloc[o[0]] for o in ordered_result]\n",
    "        most_common = max(map(lambda val: (vals.count(val), val), set(vals)))[1]\n",
    "        \n",
    "        if str(most_common) == y_val.iloc[i-ntrain]:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "            \n",
    "    print(\"Accuracy:\", accuracy(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19029, 1100)\n",
      "(1100, 1100)\n",
      "(1100, 19029) \n",
      "\n",
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 40.82515239715576\n",
      "k: 5\n",
      "Accuracy: 0.64\n",
      "Time elapsed: 40.05109643936157\n",
      "k: 25\n",
      "Accuracy: 0.44\n",
      "Time elapsed: 40.560301065444946\n"
     ]
    }
   ],
   "source": [
    "tf = X.T #term frequency\n",
    "\n",
    "idf = np.log(tf.shape[1] / ( 1 + sum(tf != 0) ))\n",
    "idf = np.diag(idf)\n",
    "\n",
    "tfidf = np.dot(tf,idf).T\n",
    "\n",
    "print(tf.shape)\n",
    "print(idf.shape)\n",
    "print(tfidf.shape, '\\n')\n",
    "\n",
    "# normalize\n",
    "tfidf = tfidf/np.sqrt(np.sum(tfidf**22))\n",
    "\n",
    "# train datasets\n",
    "train_tfidf = tfidf[:ntrain]\n",
    "\n",
    "for l in [1, 5, 25]:\n",
    "    start = time.time()\n",
    "    knn_tfidf(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How accurate is BOW versus TF-IDF? How does choice of k change the results? Is BOW or TF-IDF faster to run?*\n",
    "\n",
    "Accuracy appears to be the same for both models when k = 1, 5, and 25. The change in the choice of k remains to have the same pattern, where accuracy decreases as k increases. BOW is much faster to run than TD-IDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Are tomatoes fresh or rotten?\n",
    "\n",
    "Our next task is to classify the Rotten Tomatoes movie reviews. Briefly, approved critics can write reviews for movies, and evaluate the movie as \"fresh\" or \"rotten\". The webpage normally shows a short quote from each critic, and whether it was evaluated as fresh or rotten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the data. Inspect it a little bit to see how it is coded and organized. How many cases are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 13442\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/87745/toy-...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.newsweek.com/id/104199</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.variety.com/review/VE1117941294.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb  \\\n",
       "0         Derek Adams  fresh  114709   \n",
       "1     Richard Corliss  fresh  114709   \n",
       "2         David Ansen  fresh  114709   \n",
       "3       Leonard Klady  fresh  114709   \n",
       "4  Jonathan Rosenbaum  fresh  114709   \n",
       "\n",
       "                                                link     publication  \\\n",
       "0  http://www.timeout.com/film/reviews/87745/toy-...        Time Out   \n",
       "1  http://www.time.com/time/magazine/article/0,91...   TIME Magazine   \n",
       "2                  http://www.newsweek.com/id/104199        Newsweek   \n",
       "3  http://www.variety.com/review/VE1117941294.htm...         Variety   \n",
       "4  http://onfilm.chicagoreader.com/movies/capsule...  Chicago Reader   \n",
       "\n",
       "                                               quote          review_date  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04 00:00:00   \n",
       "1                  The year's most inventive comedy.  2008-08-31 00:00:00   \n",
       "2  A winning animated feature that has something ...  2008-08-18 00:00:00   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09 00:00:00   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10 00:00:00   \n",
       "\n",
       "   rtid      title  \n",
       "0  9559  Toy Story  \n",
       "1  9559  Toy Story  \n",
       "2  9559  Toy Story  \n",
       "3  9559  Toy Story  \n",
       "4  9559  Toy Story  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten = pd.read_csv(\"reviews.csv\")\n",
    "print(\"Number of cases:\", len(rotten))\n",
    "rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data. Retain only cases where fresh and quote are present and non-empty. Remove repeated observations (there are such in data). How many cases will be left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 12823\n"
     ]
    }
   ],
   "source": [
    "rotten = rotten[rotten.fresh != \"none\"]\n",
    "rotten = rotten.drop_duplicates()\n",
    "print(\"Number of cases:\", len(rotten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select training and validation data. You would like to split all cases into 80-20 groups.\n",
    "\n",
    "We need to find the closest training quotes for each test quote, then predict if the movie is fresh or rotten according to the quote.\n",
    "\n",
    "Following the same steps we did with the texts above:\n",
    "\n",
    "(a) Create dictionary and BOW of all quotes\n",
    "\n",
    "(b) Run k-NN with several different k's and predict if fresh or rotten. In each run, compute the accuracy.\n",
    "\n",
    "(c) Transform the data into TF-IDF form and repeat k-NN.\n",
    "\n",
    "(d) Inspect a few cases where the tomato was correctly and incorrectly predicted. Can we explain why the algorithm behaved in the way it behaved?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 1500\n",
    "nVal = 300\n",
    "\n",
    "train_df = rotten.sample(n=ntrain, random_state = 123)\n",
    "val_df = rotten.loc[~rotten.index.isin(train_df)].sample(n=nVal, random_state = 123)\n",
    "\n",
    "X_train = train_df.quote\n",
    "X_val = val_df.quote\n",
    "y_train = train_df.fresh\n",
    "y_val = val_df.fresh\n",
    "\n",
    "sentences = np.concatenate((X_train.values, X_val.values),axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "vectorizer.fit(sentences)\n",
    "X = vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created dictionary and BOW of all quotes, let's run k-NN with several different k's and predict if fresh or rotten. In each run, compute the accuracy.\n",
    "Essentially, we are doing the same thing we did above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 16.691444873809814\n",
      "k: 5\n",
      "Accuracy: 0.7533333333333333\n",
      "Time elapsed: 17.427025318145752\n",
      "k: 25\n",
      "Accuracy: 0.6866666666666666\n",
      "Time elapsed: 16.843358755111694\n"
     ]
    }
   ],
   "source": [
    "# BOW\n",
    "train_cases = X[:ntrain]\n",
    "\n",
    "for l in [1, 5, 25]:\n",
    "    start = time.time()\n",
    "    knn(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data into TF-IDF form and repeat k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6770, 1800)\n",
      "(1800, 1800)\n",
      "(1800, 6770) \n",
      "\n",
      "k: 1\n",
      "Accuracy: 1.0\n",
      "Time elapsed: 78.05132484436035\n",
      "k: 5\n",
      "Accuracy: 0.7533333333333333\n",
      "Time elapsed: 78.02384424209595\n",
      "k: 25\n",
      "Accuracy: 0.6866666666666666\n",
      "Time elapsed: 81.88916397094727\n"
     ]
    }
   ],
   "source": [
    "# TD-IDF\n",
    "tf = X.T # term frequency\n",
    "\n",
    "idf = np.log(tf.shape[1] / ( 1 + sum(tf != 0) ))\n",
    "idf = np.diag(idf)\n",
    "\n",
    "tfidf = np.dot(tf,idf).T\n",
    "\n",
    "print(tf.shape)\n",
    "print(idf.shape)\n",
    "print(tfidf.shape, '\\n')\n",
    "\n",
    "# normalize\n",
    "tfidf = tfidf/np.sqrt(np.sum(tfidf**22))\n",
    "\n",
    "# train datasets\n",
    "train_tfidf = tfidf[:ntrain]\n",
    "\n",
    "for l in [1,5,25]:\n",
    "    start = time.time()\n",
    "    knn_tfidf(l)\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What worked better: reviews or text pages? What worked better: BOW or TF-IDF?*\n",
    "\n",
    "We can say once again that: both of our models are best when k = 1, with an accuracy of 1.0. Accuracy decreases as we increase k. BOW and TF-IDF seemed to have similar accuracies with the same k's again, just as we saw in the last section. When we compare reviews vs text pages, we see that with reviews, accuracy decreases along with k at a lesser rate than text pages, showing us that reviews may have worked better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
